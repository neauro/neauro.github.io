
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>liwanag</title>
  <meta name="author" content="nadine a.">

  
  <meta name="description" content="CHOCOBOS. NOOOOO Feb 15th, 2011 So I&#8217;ve been playing social games as research for my Informatics class, and in general been pretty skeptical &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.neauro.com/blog/page/25">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="liwanag" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<link href="http://fonts.googleapis.com/css?family=Metrophobic:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-46467190-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">liwanag</a></h1>
  
    <h2>things i learn, things i like</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:blog.neauro.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/15/chocobos-nooooo/">CHOCOBOS. NOOOOO</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-15T00:00:00-08:00" pubdate data-updated="true">Feb 15<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-HRBgV5lMWMQ/TVq_JofqSRI/AAAAAAAAAHM/09kAvAvaRVA/s1600/chochoco.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="574" src="http://1.bp.blogspot.com/-HRBgV5lMWMQ/TVq_JofqSRI/AAAAAAAAAHM/09kAvAvaRVA/s640/chochoco.jpg" width="640" /></a></div><br />So I&#8217;ve been playing social games as research for my Informatics class, and in general been pretty skeptical of the whole thing (outside of FarmVille, which I find myself enjoying slightly more than the others, maybe just because it&#8217;s a farm sim and it feeds my &#8220;pastoral ideal,&#8221; which I recently learned that I possess thanks to <em>The Omnivore&#8217;s Dilemma</em>) &#8211; and then.<br /><br /><em>A chocobo game?</em><br /><br /><span class="shh"><em>I love birds/chickens/chocobos/the pastoral ideal.  It&#8217;s even red.  Red is my favorite color.</em></span><br /><br />It&#8217;s over.  It&#8217;s over for me.<br /><br />.___.</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/games/'>games</a>, <a class='category' href='/blog/categories/video-games/'>video games</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/11/operating-systems-notes-virtual-memory/">Operating Systems Notes [Virtual Memory, Page Tables, TLBs]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-11T00:00:00-08:00" pubdate data-updated="true">Feb 11<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So in case <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">it wasn&#8217;t clear already</a>, <a href="http://en.wikipedia.org/wiki/Virtual_memory">virtual memory</a> is a memory management technique which accomplishes these things:<ul><li>hides fragmentation of physical memory from programs</li><li>uses hardware memory more efficiently than systems without virtual memory</li><li>lets a program be designed as though there&#8217;s only one hardware memory (rather than one memory split up between different processes, I think?)</li></ul><br />An important aspect of implementing virtual memory is page tables.  A page table translates a program&#8217;s virtual address (used to refer to a function or variable or whatnot) into a physical address (which is the actual location of that function&#8217;s code data, or the variable&#8217;s value data).  Page tables make it so that programs can only be partially loaded into memory.  <strong>So, what happens when a program tries to access a part of its code which isn&#8217;t loaded into memory?<br /><br />A PAGE FAULT.</strong><br /><br />When a page fault happens,<ol><li>the OS is given an <a href="http://nuubu.blogspot.com/2011/01/operating-system-notes-chapter-1.html">interrupt</a></li><li>the OS saves the state of the running process, then searches (in the appropriate vector) for the page fault handler routine)</li><li>the page fault handler routine will find or create (through eviction) a page frame into which to load the page that the program needs</li><li>then it will find that page on the disk and place it into the now-free page frame</li><li>then it will fix up the page table entry &#8211; marking it &#8220;valid,&#8221; setting the &#8220;referenced&#8221; and &#8220;modified&#8221; bits to false, setting the pointers properly</li><li>finally, the process is placed back into the ready queue</li></ol><br />Anyway, it&#8217;s getting late and I want to go to bed so for now I&#8217;ll just skip to<br /><br /><br /><span class="sig">Translation Lookaside Buffers (TLBs)</span><br />to whom we must extend our gratitude for not making page tables awful.  Think about it: if you have a virtual address and you need to look into the page table and then into the physical address in order to actually obtain some value, that&#8217;s a <em>lot</em> of overhead.<br /><br />To make this more efficient, you want to make fetching from a virtual address just about as efficient as fetching from a physical address.  Which you can do with an extra piece of hardware, a cache inside the CPU.<br /><br />Thus, virtual-to-physical translations are cached in the hardware itself, the TLB.  The TLB translates virtual page numbers into page frame numbers (<em>not physical addresses</em>), and can do it in a single machine cycle.  The TLB in turn is managed by the memory management unit (MMU), which is what calculates the physical address from the page table entry and an offset.<br /><br />TLBs exploit the fact that processes have good temporal locality and spatial locality.  This is a fancy way of saying that processes tend to<ul><li>use data/code they have recently used</li><li>use data/code that is close to data/code they have recently used</li></ul>Which is why <em>caching</em>, or saving that data in an easily accessible place (as you may cache your potato chips, water bottles, and chocolate beneath the bedside  table) is a good idea.<br /><br />So, the TLB does the translation between virtual addresses and page frame numbers, and when it misses &#8211; when it can&#8217;t find a page frame number &#8211; the translation is saved into the TLB by the OS.<br /><br />In order for TLBs to work, the OS must make sure the TLB and page tables are consistent and up-to-date, and <strong>when a context switch happens, the TLB must be completely flushed</strong>, which means that context switching is still an expensive operation &#8211; all those cached translations, that optimization, disappears.  (The TLB needs to be flushed rather than saved and loaded with the rest of the process state because there&#8217;s no guarantee that other processes wouldn&#8217;t mess around with the data the TLB was keeping track of, and to keep the TLB up-to-date when it isn&#8217;t being presently used by a process is expensive.)<br /><br /><br /><br />Sources:<br /><a href="http://en.wikipedia.org/wiki/Virtual_memory">Wikipedia: Virtual memory</a><br />lecture 11a notes</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/11/operating-systems-notes-memory/">Operating Systems Notes [Memory Management]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-11T00:00:00-08:00" pubdate data-updated="true">Feb 11<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">What&#8217;s so cool about memory management anyway bro</span><br />So unlike way back when in the time of punchcards &amp; etc., we use computers which are capable of <strong>multiprogramming</strong>, a feature of which is the ability to have multiple processes and jobs in memory all at once.<br /><br />We&#8217;ve already looked at ways that an operating system&#8217;s <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-5-cpu.html">processing power</a> can be utilized effectively when you have many different processes executing simultaneously, but how can memory &#8211; also a scarce resource in a computer &#8211; be distributed across processes?  The goal of memory management is to <strong>maximize memory utilization and system throughput</strong>.<br /><br />You also have to make sure that you can manage memory so as to:<br /><ol><li><strong>Protect</strong>: that is, make sure processes execute in isolation, so they don&#8217;t interfere with each other</li><li><strong>Translate fast</strong>: that is, make sure that memory lookups are speedy despite the fact that protection kind of slows stuff down</li><li><strong>Context switch fast</strong>: that is, make sure memory hardware is updated when old processes are removed from the CPU and new processes are given to it</li></ol><br />On a hardware level, when you&#8217;re dealing with memory, you&#8217;re really messing around with <strong>base registers</strong> and <strong>limit registers</strong>.   Base registers contain the address of a start of a program,  and limit registers contain the length of the program.  Both of these things define the scope of a program&#8217;s memory.<br /><br />Programs get their code and data loaded into memory so that they can be run in processes.  It&#8217;s important to keep the memory that processes use separate, so that they don&#8217;t interfere with each other, overwriting the other program&#8217;s code and making it crash and such.  The memory that a program has is allocated is called its <strong>address space</strong>.  In the olden days, if a program couldn&#8217;t fit into memory, then you&#8217;d have to manually overwrite parts of the code that you weren&#8217;t using presently.<br /><br /><br /><span class="sig">Virtual Memory</span><br />Virtual memory is an abstraction provided by the operating system for memory management.  Thanks to virtual memory, we can do cool things like:<br /><ul><li>allow programs to execute even if their entire address space isn&#8217;t in physical memory</li><li>let programs execute with less RAM than they really &#8220;need&#8221;</li><li>isolate processes from each other so that they can&#8217;t name addresses that other processes can use</li></ul>This is mainly because programs don&#8217;t really use all of the code that they&#8217;re written with &#8211; for instance, a program with if-statements will either execute one branch of the if-statement or the other, and there&#8217;s no real need to allocate space for code that isn&#8217;t run.<br /><br />On a hardware level, virtual memory relies on translation-lookaside buffers (TLB&#8217;s), page tables, page fault handling&#8230;you&#8217;ll also need to deal with swapping and segmentation.  <strong>Swapping</strong> is the memory-equivalent of context switching for processing power.  When you do a context switch between processes, you remove the old process from using CPU and allocate that CPU to the new process; in swapping, you remove memory from the previous process and give it to the new one.<br /><br /><br /><span class="sig">Virtual Addresses</span><br />So, this whole time when we&#8217;ve been talking about how <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-2-3.html">a process consists of an address space</a> (along with at least one thread and OS resources), what we&#8217;ve really meant is that processes have a set of <strong>virtual addresses</strong>.  Once more: a process&#8217;s address space is its set of virtual addresses.<br /><br />And what are virtual addresses?  They are the layer of abstraction between a process and physical memory.  When the CPU executes instructions from a loaded program, it uses the virtual addresses for pointers, arguments to load and store instructions, and so on.  Virtual addresses must be translated by hardware into physical addresses, the actual location of the data stored on disk.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-KotutHv0Kkk/TVTbDb2stkI/AAAAAAAAAGE/c_t2mc_tACA/s1600/viraddr1.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="226" src="http://4.bp.blogspot.com/-KotutHv0Kkk/TVTbDb2stkI/AAAAAAAAAGE/c_t2mc_tACA/s320/viraddr1.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">so, here we&#8217;ve got: process p&#8217;s pointer, which points to a virtual address in p&#8217;s address space. &nbsp;that in turn points to a physical address in physical memory.  the physical address is what points to the actual data.</td></tr></tbody></table><br /><br /><span class="sig">How do you translate virtual addresses into physical addresses?</span><br />Virtual addresses (in the process address space) and physical addresses (on disk) don&#8217;t correspond exactly to each other &#8211; that is, a virtual address in space 0 doesn&#8217;t necessarily point to a physical address in space 0.  So, how does a virtual address translate to a physical address?<br /><br />To translate in the olden days, the physical memory would be partitioned, in one of two ways:<br /><ol><li><strong>Fixed partitions.</strong>  The physical memory would be broken up into fixed-size partitions, so that the physical address could be obtained by adding the virtual address and the base register.  When a context switch happened, a new base register would be loaded.  This was a simple way of doing things but has <strong>fragmentation problems</strong> &#8211; both <strong>internal fragmentation</strong> (which happens when the physical memory partition is larger than what the program needs) and <strong>external fragmentation</strong> (which happens when you may have two small partitions remaining, and one large job which won&#8217;t fit into each separately).<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-Ty-M47nOJzo/TVTdQWMAdkI/AAAAAAAAAGM/ftBjaeeoabo/s1600/viraddr2.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="203" src="http://4.bp.blogspot.com/-Ty-M47nOJzo/TVTdQWMAdkI/AAAAAAAAAGM/ftBjaeeoabo/s320/viraddr2.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">with fixed partitions,<br />physical address = virtual address + base register<br />the limit register check is to make sure you don&#8217;t overstep physical memory</td></tr></tbody></table><br /></li><li><strong>Variable partitions.</strong> In this case, the physical memory would be broken up into variable-size partitions, the size dependant on the program.  Again, the physical address is equal to the virtual address plus the base register.  Variable partitioning <strong>fixes internal fragmentation</strong>, since you won&#8217;t allocate more than a program needs and therefore waste space that other programs could use &#8211; <strong>but you still have external fragmentation</strong>, because as you load and unload jobs, holes are left scattered behind.  (This is slightly different than external fragmentation in fixed partition systems.)<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-4zihtB6CQNQ/TVTeWbpF6jI/AAAAAAAAAGU/0-y3xwKJIkI/s1600/viraddr3.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="245" src="http://1.bp.blogspot.com/-4zihtB6CQNQ/TVTeWbpF6jI/AAAAAAAAAGU/0-y3xwKJIkI/s320/viraddr3.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">with variable partitions,<br />physical address = virtual address + base register<br />the limit register makes sure you don&#8217;t overstep memory<br />the black parts denote unused holes in the memory 3:</td></tr></tbody></table></li></ol><br /><br />One way to deal with external fragmentation is to be like,<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-iVkxoUAgHa0/TVTfpWKPs_I/AAAAAAAAAGc/5ngILCCIYpQ/s1600/viraddr4.jpg" imageanchor="1"><img border="0" height="234" src="http://3.bp.blogspot.com/-iVkxoUAgHa0/TVTfpWKPs_I/AAAAAAAAAGc/5ngILCCIYpQ/s320/viraddr4.jpg" width="320" /></a></div><br />and basically push all the allocated physical memory together.  Which is bad because you have to do this manually and like, all the time.<br /><br />So, a better way to do things in general is to be like, PAGES, BRO.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-29MhcnKDPZQ/TVTf8yOllPI/AAAAAAAAAGk/xqYlIwU95HQ/s1600/viraddr5.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="250" src="http://3.bp.blogspot.com/-29MhcnKDPZQ/TVTf8yOllPI/AAAAAAAAAGk/xqYlIwU95HQ/s320/viraddr5.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">PAGES. &nbsp;YE</td></tr></tbody></table><br /><br /><span class="sig">Pages and Page Tables</span><br />So with pages, processes view their address space as some memory ranging from indexes 0 to N, but in reality the mapping of those address spaces to physical addresses points every which way all over the disk.  The program doesn&#8217;t know this at all, and isolation is still provided to all program&#8217;s because a program still can&#8217;t reference memory outside of its virtual address space.<br /><br />So.  A virtual address is comprised of a virtual page number (VPN), as well as some offset.  A physical address is comprised of a page frame number (PFN), as well as some offset.  Now, to translate from a virtual address to a physical address, you need to divide the address space into equal-sized &#8220;pages,&#8221; and then use one more thing: the <strong>page table</strong>.  The page table contains the mapping between a virtual address&#8217;s VPN and a physical address&#8217;s PFN, and this is how a program with a virtual address can access physical memory, memory on disk.  Once more, for good measure: a page table maps a <em>virtual address page</em> to a <em>physical page frame</em>.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/_SdPKamJbrgg/TVThyWocAlI/AAAAAAAAAGs/cQVcDkDCC0U/s1600/viraddr6.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="215" src="http://4.bp.blogspot.com/_SdPKamJbrgg/TVThyWocAlI/AAAAAAAAAGs/cQVcDkDCC0U/s320/viraddr6.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">it&#8217;s easy, right?</td></tr></tbody></table><br /><br />Page tables contain <strong>page table entries (PTEs)</strong>, which look something like this:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TVTiaKBOuiI/AAAAAAAAAG0/EutComkh8Jg/s1600/viraddr7.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="91" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TVTiaKBOuiI/AAAAAAAAAG0/EutComkh8Jg/s320/viraddr7.jpg" width="320" /></a></div><ul><li>the <strong>valid bit</strong> says whether or not this PTE can be used &#8211; that is, whether or not the virtual address is valid, meaning it actually maps to some physical address, which points to a location in physical memory.</li><li>the <strong>referenced bit</strong> says whether the page has been accessed &#8211; that is, whether it&#8217;s been read from or written to at all</li><li>the <strong>modified bit</strong> says whether or not the page is dirty, meaning a write has occurred to that page</li><li>the <strong>protection bits</strong> control which operations (read, write, execute, etc.) are allowed to be used on this page</li><li>and finally, the PFN determines the &#8220;physical page,&#8221; the location in physical memory that the given virtual address points to.  Like how a base register contains the starting address of a process&#8217;s virtual address space, a physical page&#8217;s start address is determined by the PFN.</li></ul><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-IjOgv0A9WCU/TVTurOC7yJI/AAAAAAAAAHE/1vfxhYR5OlA/s1600/viraddr9.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="232" src="http://2.bp.blogspot.com/-IjOgv0A9WCU/TVTurOC7yJI/AAAAAAAAAHE/1vfxhYR5OlA/s320/viraddr9.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">here&#8217;s the picture from earlier without the page table photoshopped out of it</td></tr></tbody></table><br /><br /><strong>The great thing about paging</strong> is that makes it easy to allocate physical memory to a program &#8211; physical memory is now ordered in a list of frames, and when you want to allocate it, just remove it from the list of &#8220;free&#8221; frames.  This solves external fragmentation and all the troublesome-ness of managing the holes left behind from loading and unloading programs.<br /><br />And, it lends itself naturally to <strong>virtual memory</strong>, because a program doesn&#8217;t need to be completely resident in the memory anymore &#8211; only partially, only the parts that you care about right now (or soon).  If it so happens that you need code that is not presently in memory (which you&#8217;ll know, because when you use a virtual address to access something not in memory, the valid bit in the PTE will cry out), you take a <strong>page fault</strong>, and the code or data that you need will be brought into memory.<br /><br />Remaining problems: internal fragmentation, since a process still may not use memory in exact multiples of pages.  Also, there&#8217;s a great overhead in referencing anything, since instead of accessing that thing directly, you&#8217;re making two look-ups, first through the page table, and then into physical memory itself.  <span class="shh">(This can be solved with TLBs &#8211; more on that later.)</span><br /><br />The other problem: page tables can be huge.  Consider that each process has its own address space, which means you need one page table entry per page in the address space.  Operating systems typically have separate page tables per process, and things can get huge fast.  The solution to this is to&#8230;page the page tables lol.<br /><br /><br /><span class="sig">And yet another way to translate virtual addresses into physical addresses: segmentation</span><br />To do segmentation, partition not the physical memory, but the address spaces, into logical units: one partition for stack, one for code, one for the heap, one for subroutines&#8230;<br /><br />A virtual address that is a part of this address space will then consist of a <strong>segment number</strong> and an <strong>offset</strong>.<br /><br /><strong>The good thing about this: it&#8217;s more logical</strong>, since without segmentation, what the linker does during compilation is take a bunch of modules that call each other and linearizes them.  These modules are all independent and are treated that way when the address space is segmented.  Segmentation is also a natural extension of variable-sized partitions; where there&#8217;s one variable partition per process, there&#8217;s many segments per process.  Segmentation also facilitates sharing and reuse of code.<br /><br /><strong>Disadvantages: just like a variable partition system, segmentation can have all the horrific external fragmentation, even if linking is simpler.</strong><br /><br />On a hardware level, you would need a segment table with multiple base/limit register pairs, one per segment in the address space.  The physical address would be yielded by adding the virtual address offset to the base address of the segment.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TVTsVUM3gXI/AAAAAAAAAG8/rfJKLzVUE18/s1600/viraddr8.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="238" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TVTsVUM3gXI/AAAAAAAAAG8/rfJKLzVUE18/s320/viraddr8.jpg" width="320" /></a></div><br />Anyway, to fix the problem that segmentation has with external fragmentation, you can mix segmentation and paging.  Use segments to manage logical units, and then use paging to partition segments into fixed-size chunks.  Each segment will have its own page table (rather than there being one page table per address space), and memory allocation once again becomes easy and cool, without external fragmentation problems.<br /><br /><br /><br />Sources:<br />lecture 10 notes<br /><a href="http://www.science-dictionary.com/definition/base-register.html">Science-Dictionary: base register</a><br /><a href="http://answers.yahoo.com/question/index?qid=20090520065552AAOWEvZ">Yahoo Answers: Base and limit register?</a><br />section 5 notes</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/05/okay-dude-so-planting-nachos-is/">Okay Dude, So, Planting Nachos Is Actually Kind of Cute</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-05T00:00:00-08:00" pubdate data-updated="true">Feb 5<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4ySbyJ4dI/AAAAAAAAAFk/Ipk2855l4uk/s1600/nachos1.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="534" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4ySbyJ4dI/AAAAAAAAAFk/Ipk2855l4uk/s640/nachos1.jpg" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TVBwgqjNpbI/AAAAAAAAAF0/qtPvgGw2FOI/s1600/nachos01.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="532" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TVBwgqjNpbI/AAAAAAAAAF0/qtPvgGw2FOI/s640/nachos01.jpg" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TVByO8ZIlfI/AAAAAAAAAF8/NTGFfh633Ko/s1600/nachos02.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="532" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TVByO8ZIlfI/AAAAAAAAAF8/NTGFfh633Ko/s640/nachos02.jpg" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4yXQ69pVI/AAAAAAAAAFs/Imea2ZBUA_I/s1600/nachos3.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="532" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4yXQ69pVI/AAAAAAAAAFs/Imea2ZBUA_I/s640/nachos3.jpg" width="640" /></a></div><br />Other things I approve of:<br /><ul><li>being able to sell bushels of stuff</li><li>apparently being able to craft stuff when I reach level 25 (after I get tons of people to help me build the wineries and craft areas and whatever, I guess)</li><li>FINALLY FINDING A QUEEN BEE OMG AUGH FINALLY</li></ul></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/games/'>games</a>, <a class='category' href='/blog/categories/video-games/'>video games</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/04/operating-systems-notes-deadlocks/">Operating Systems Notes [Deadlocks]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-04T00:00:00-08:00" pubdate data-updated="true">Feb 4<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So.  Real talk.  I guess deadlocks kind of suck.<br /><br /><strong>A deadlock is an irreducible circular dependence</strong>.  You would use locks  to <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-6.html">synchronize</a> threads and keep them from messing with each other when they&#8217;re working on shared resources, like a global variable.<br /><br />When a deadlock happens, the two threads can&#8217;t advance because they each own a lock to a resource that the other one needs in order to continue on.<br /><br />Deadlocks can be visible as cycles.  In this next picture, process P1 has R1 and only needs R2 to proceed.  However, P2 owns R2 and needs R1 to proceed.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw0_-YLnBI/AAAAAAAAAFM/Fqt7QcRHTOM/s1600/deadlock1.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="166" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw0_-YLnBI/AAAAAAAAAFM/Fqt7QcRHTOM/s320/deadlock1.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">and so, unhappiness abounds</td></tr></tbody></table><br /><br />A cycle doesn&#8217;t necessarily always signal a deadlock, however, as in this picture.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TUw2F2J0RXI/AAAAAAAAAFU/WT2g1Yhukg8/s1600/deadlock2.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="320" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TUw2F2J0RXI/AAAAAAAAAFU/WT2g1Yhukg8/s320/deadlock2.jpg" width="206" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">yaaaaay</td></tr></tbody></table><br />Here, you would think there would be a cycle involving the processes P1 and P3, and the resources R1 and R2.  But, P2 could potentially release its ownership of the resource R1, and then P1 would be able to advance, and then the cycle would be broken.   Thus the <em>irreducible</em> part of the definition of deadlocks.  A graph can be reduced if a thread within that graph can have all of its requests granted.<br /><br /><br />In the case of code, a deadlock could look something like this.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw4Mx7zGTI/AAAAAAAAAFc/11kExpNbcBs/s1600/deadlock3.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="124" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw4Mx7zGTI/AAAAAAAAAFc/11kExpNbcBs/s320/deadlock3.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">:(</td></tr></tbody></table><br />A deadlock happens in this case if Thread1 and Thread2 are running simultaneously, and Thread1 acquires lock A and Thread2 acquires lock B.  Then, they both need the lock that the other thread has to proceed.  No advancement.<br /><br />One way to deal with a case like this would be to make a function which would grab two locks for a thread simultaneously, instead of one at a time.<br /><br /><br /><span class="sig">Avoiding Deadlocks</span><br />There are three methods you can use to avoid deadlocks: preventative, avoidance, and detection.<br /><br /><strong>Prevention</strong> is a static method of avoidance.  You can make sure each thread obtains all the locks that it needs, and waits until all are available before moving.  The downside to this method is that you may end up making the system move more slowly &#8211; ideally you want some threads to do what work they can do with what they&#8217;ve got, not having to wait.  This is called <em>hold and wait</em>.<br /><br />In <em>circular wait</em>, resources are ordered, which means threads obtain locks to the resources in sequence.  This works because you won&#8217;t have threads grabbing things out of order and causing deadlocks.  But there&#8217;s disadvantages too: new locks will need to be added to the right spot, <em>all</em> resources would have to be ordered, including drives and networks and things, and how would you determine how to order those resources?  It&#8217;s kind of messy.<br /><br /><strong>Avoidance</strong> is a dynamic way of dealing with deadlocks, meaning I think that the system handles it, rather than the threads themselves.  There&#8217;s also a <em>circular wait</em>, but it&#8217;s different.  In avoidance, each thread states how many resources it needs max, and the system uses the Banker&#8217;s Algorithm on the request to see if the system could allocate that max to that thread, and still have enough resources remaining to let all the other threads finish their execution.<br /><br />Basically, with every thread&#8217;s request for its max resources, do this:<ul><li>Pretend that you granted the request</li><li>Pretend that you granted everyone else&#8217;s requests too</li><li>Can the resulting graph of threads and resources (as above) be reduced?</li><li>If yes, allocate the requested resource to that first requesting thread.  If not, block dat thread!</li></ul><br />With <strong>detection</strong>, also dynamic, the technique is to check to see if there&#8217;s a deadlock, and then eliminate it when you find one.  I&#8217;m pretty sure databases do a lot of stuff like this.  It&#8217;s easy to see if a deadlock has occurred already because the OS or relevant scheduler is aware of the processes and resources that are using/in use, so once you&#8217;ve found a deadlock, you should restart one of the threads, and hopefully that thread will have enough resources to run again in the next millisecond or two.  <br /><br /><br /><br />Sources:<br />section 5 notes<br />lecture 9 notes<br /><a href="http://en.wikipedia.org/wiki/Deadlock#Detection">Wikipedia: Deadlock Detection</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/30/incorporating-actionscript-30-code-with/">Incorporating ActionScript 3.0 Code With a Flex Project</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-30T00:00:00-08:00" pubdate data-updated="true">Jan 30<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So my project of <a href="http://nuubu.blogspot.com/2010/12/problem-how-do-i-use-flex-components-to.html">incorporating Flex UI with an ActionScript project</a> has just become wanting to embed the entire ActionScript project into the Flex project, so that you don&#8217;t need to use the <code>SWFLoader</code> at all to show the project.<br /><br />Luckily this is pretty easy.  As an example, take the code from a previous small project like <a href="http://nuubu.blogspot.com/2010/12/getting-sandy3d-312-working-on-flash.html">this Sandy project</a>, which does nothing but show a cone shape.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TPh_TU109CI/AAAAAAAAAAM/q_A6cDrKYGE/s1600/hellosandy.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="267" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TPh_TU109CI/AAAAAAAAAAM/q_A6cDrKYGE/s320/hellosandy.jpg" width="320" /></a></div><br /><pre class="brush: text">package<br />{<br />import flash.display.Sprite;<br />import flash.events.Event;<br /><br />import sandy.core.Scene3D;<br />import sandy.core.data.*;<br />import sandy.core.scenegraph.*;<br />import sandy.primitive.*;<br /><br />public class HelloSandy extends Sprite<br />{<br />private var scene:Scene3D;<br />private var camera:Camera3D;<br /><br />public function HelloSandy()<br />{<br />// We create the camera<br />camera = new Camera3D( 300, 300 );<br />camera.x = 0;<br />camera.y = 100;<br />camera.z = -400;<br />camera.lookAt(0,0,0);<br /><br />var root:Group = new Group;<br /><br />var myCone:Cone = new Cone("theObj1",50, 100);<br /><br />root.addChild(myCone);<br /><br />scene = new Scene3D( "scene", this, camera, root );<br /><br />addEventListener( Event.ENTER_FRAME, enterFrameHandler );<br />}<br /><br />// The Event.ENTER_FRAME event handler tells the world to render<br />private function enterFrameHandler( event : Event ) : void<br />{<br />scene.render();<br />}<br /><br />}<br />}</pre><br />Then, make a <strong>New Flex Project</strong> in Adobe Flash Builder, and make it so that it says this:<br /><pre class="brush: xml">&lt;?xml version="1.0" encoding="utf-8"?&gt;<br />&lt;s:Application xmlns:fx="http://ns.adobe.com/mxml/2009" <br />      xmlns:s="library://ns.adobe.com/flex/spark" <br />      xmlns:mx="library://ns.adobe.com/flex/mx"<br />                           minWidth="955" minHeight="600"<br />      creationComplete="initApp()"&gt;<br /><fx:script><br />  &lt;![CDATA[<br />   import mx.core.UIComponent;<br />   <br />   public function initApp():void {<br />    var myApp:HelloSandy = new HelloSandy();<br />    var container:UIComponent = new UIComponent();<br />    container.height = 600;<br />    container.left = 200;<br />    addElement(container);<br />    container.addChild(myApp);<br />   }<br />  ]]&gt;<br /> </fx:script><br /> <s:button label="Button" x="140" y="355"><br /></s:button><br /></pre><br />What this does:<br />Line 12: create a new instance of the ActionScript project, HelloSandy<br />Line 13: create a new instance of <code>UIComponent</code><br />Line 14, 15: change the height and position of the <code>UIComponent</code><br />Line 16: add the <code>UIComponent</code> to the <code>stage</code>, which handles the display of objects (a little more on the stage <a href="http://nuubu.blogspot.com/2011/01/flexas3-errors-with-stage-and-event.html">here</a>)<br />Line 17: add the HelloSandy object as a child to <code>UIComponent</code>, which will make it display<br /><br />The button is just there to show that I can still use Flex UI components.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TUXuuNoxXlI/AAAAAAAAAFA/99rs1S3w-zw/s1600/helloflexsandy.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="287" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TUXuuNoxXlI/AAAAAAAAAFA/99rs1S3w-zw/s320/helloflexsandy.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">awwwww yeaahhh</td></tr></tbody></table><br /><br /><span class="sig">An extra note:</span><br />Once I did this with my real project (not the HelloSandy example above), I got this error:<br /><br /><code>Error #2044: Unhandled IOErrorEvent:. text=Error #2032: Stream Error URLStream</code><br /><br />I&#8217;m pretty sure it was because my &#8220;display&#8221; class, which was being added to the <code>UIComponent</code> had to make use of another class, which it made an instance of in its constructor.  This second class used <code>URLStream</code>, and got an error maybe because of variable scope.<br /><br />To solve this I basically just made a new instance of that second class, then passed it into the display class constructor, instead of letting the display class make an instance itself.<br /><br /><br />Sources:<br /><a href="http://livedocs.adobe.com/flex/3/html/help.html?content=components_04.html">Adobe: Using the UIComponent Class</a><br /><a href="http://www.judahfrangipane.com/blog/2007/01/01/error-2044-unhandled-ioerrorevent-texterror-2038-file-io-error/">judah&#8217;s blog: Error #2044: Unhandled IOErrorEvent:. text=Error #2038: File I/O Error.</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/actionscript/'>actionscript</a>, <a class='category' href='/blog/categories/flash/'>flash</a>, <a class='category' href='/blog/categories/flex/'>flex</a>, <a class='category' href='/blog/categories/programming/'>programming</a>, <a class='category' href='/blog/categories/sandy3d/'>sandy3d</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/30/how-do-you-make-flex-application/">How Do You Make a Flex Application Send Data to a PHP Server?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-30T00:00:00-08:00" pubdate data-updated="true">Jan 30<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
How do you make a Flex project able to read/write files?<br />There are a couple objects like <code>File</code> and <code>FileStream</code> which make it so that an Adobe AIR application can access the user&#8217;s filesystem, but to send and load data from a server, you can use <code>URLLoader</code>, <code>URLRequest</code>, and <code>URLVariables</code>.<br /><br />A summary:<ul><li><strong>URLLoader</strong> downloads data from a URL as text, binary data, or URL-encoded variables.  It&#8217;s useful for downloading textfiles, XML, etc. to be used in a data-driven application.  So: it&#8217;s for use by a Flash application to retrieve data from a URL.</li><li><strong>URLRequest</strong> is an object which contains all of the information in one HTTP request.  It initiates URL downloads by being passed to the <code>load()</code> methods of <code>Loader, URLLoader</code> classes.  Note: By default you can only load data if the application loading and the URL it&#8217;s loading from at in the same domain.  So an application on whatever.com can only load data from somewhere else on whatever.com.</li><li><strong>URLVariables</strong> allow you to transfer variables between an application and a server.  It&#8217;s used with methods of the <code>URLLoader</code> class, with the <code>data</code> property of the <code>URLRequest</code> class, and additional functions in the <code>flash.nete</code> package.</li></ul><br />Basic workflow goes like:<ol><li>In the Flash/Flex application, create an instance of <code>URLVariables</code>, and add variables to it.  For instance, if you want to be able to retrieve data associated with &#8220;username,&#8221; you&#8217;ll want to do something like <code>URLVariablesObject.username = "username"</code></li><li>Make a page on your server which will extract the variables and work with them.  For example, a page <code>login.php</code>, with code like <code>$username = $_POST["username"]</code></li><li><code>URLRequest</code> contains the data you want to send to the server.  Specify the URL of the server page you want to send data to, set its <code>data</code> to be your URLVariables object, and set its <code>method</code> to be <code>URLRequestMethod.POST</code> if you want to send data to the server page as POST.</li><li><code>URLLoader</code> sends the <code>URLRequest</code> to the server and handles the return.  Create an instance of <code>URLLoader</code>, specify its <code>dataFormat</code> to be that of <code>URLLoaderDataFormat.VARIABLES</code>, and then use the <code>load</code> function to load the <code>URLRequest</code> object specifed earlier.  Add event listeners to handle what happens when the data has been sent to the URL, and what happens if there is an error loading the URL.</li><li>Make server page read the URLVariables with something that looks like <code>$username = $_POST["username"];</code></li></ol><br />A good way to send data to a server page is to wrap up the <code>URLRequest</code> and <code>URLLoader</code> stuff into one class or function, which will receive only the url to send the data to, and URLVariables to send.<br /><br />So, here&#8217;s an example which sends a simple &#8220;test&#8221; string to some server page somewhere.  If it&#8217;s a success, it changes a <code>Label</code> to say so, and if it&#8217;s an error, it changes a <code>Label</code> to say that too.  (I&#8217;ve pretty much taken and only slightly altered from <a href="http://tush.wordpress.com/2007/07/20/actionscript-3-using-urlloader-to-send-and-load-server-variables/">another blog</a>):<br /><pre class="brush:xml">&lt;?xml version="1.0" encoding="utf-8"?&gt;<br /><s:Application xmlns:fx="http://ns.adobe.com/mxml/2009" <br />      xmlns:s="library://ns.adobe.com/flex/spark" <br />      xmlns:mx="library://ns.adobe.com/flex/mx" minWidth="955" minHeight="600"><br /> <fx:Script><br />  &lt;![CDATA[<br />   // send test data to server page<br />   protected function sendDataToServer(event:MouseEvent):void<br />   {<br />    var request:URLRequest = new URLRequest(sendToURL);<br />    var loader:URLLoader = new URLLoader();<br />    var variables:URLVariables = new URLVariables();<br />  <br />    variables.test = "test";<br />    loader.dataFormat = URLLoaderDataFormat.TEXT;<br />    request.data = variables;<br />    request.method = URLRequestMethod.POST;<br />    loader.addEventListener(Event.COMPLETE, onSuccess);<br />    loader.addEventListener(IOErrorEvent.IO_ERROR, onError);<br />    loader.load(request);<br />    sendDataToServerLabel.text= "Data sent: '" + variables.test + "'";<br />   }<br /> <br /><br />   // called when URLLoader returns successfully<br />   // prints parameters and messages of event<br />   private function onSuccess(event:Event):void<br />   {<br />    var loader:URLLoader = URLLoader(event.target);<br />    dataReceivedLabel.text = "Data received by server: success!"<br />   }<br />   <br />   // called when URLLoader returns unsucessfully<br />   // prints error message<br />   private function onError(event:IOErrorEvent):void<br />   {<br />    dataReceivedLabel.text = "Error loading URL.";<br />   }<br />  ]]&gt;<br /> </fx:Script><br /><s:Label x="715" y="444" id="dataReceivedLabel"/><br /></pre><br /><span class="sig">Possible errors:</span><br /><code>Error: Error #2101: The String passed to URLVariables.decode() must be a URL-encoded query string containing name/value pairs.</code><br /><br />I got this error fixed after changing this line &#8211;<br /><br /><code>loader.dataFormat = URLLoaderDataFormat.VARIABLES;</code><br /><br />to<br /><br /><code>loader.dataFormat = URLLoaderDataFormat.TEXT;</code><br /><br />What this does (I think) is makes it so that the returning HTML page data from the server page is encoded into a <code>TEXT</code> type instead of a <code>VARIABLES</code> type.  That Flash can&#8217;t reconstruct the HTML data into <code>VARIABLES</code> seems to be a known error, and all you can do now is convert the returning HTML data into <code>TEXT</code>, and then into <code>VARIABLES</code> pairs.<br /><br /><br /><br /><span class="sig">How do you send an array to a PHP page?</span><br />For now, I just want a PHP file on the webserver to take the data the Flex app gives it, and then write it to a file.  The <code>variables</code> object (of type <code>URLVariables</code>)  <br />above has a &#8221;<code>test</code>&#8221; field, which I can retrieve easily in PHP by writing something like <code>$var = $_POST["test"]</code>, but I guess if you want to send an array this way, the easiest way to do it would be to first format the array.  i.e.<ol><li>In Flex, convert the array to a string</li><li>In PHP, retrieve the array, and then split the string and use it.</li></ol><br />Alternatively, you could use <code><a href="http://livedocs.adobe.com/flex/3/html/data_access_2.html">HTTPService</a></code> (which also works with Rails, wooo).  But reading about it in the Adobe documentation, it seems that <code>HTTPService</code> might be more useful for when you&#8217;re working with PHP and a database and want to perform queries or format query results.  All I want to do is send an array of points (each containing x, y, and z) coordinates over, so&#8230;splitting and joining stuff up in PHP it is.<br /><br /><br /><br />Sources: <br />Adobe: <a href="http://livedocs.adobe.com/flex/3/html/help.html?content=Filesystem_08.html">Workflow for reading and writing files</a>, <a href="http://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/flash/net/URLLoader.html">URLLoader</a>, <a href="http://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/flash/net/URLRequest.html">URLRequest</a>, <a href="http://livedocs.adobe.com/flex/3/html/help.html?content=data_access_2.html">Using HTTPService components</a><br /><a href="http://tush.wordpress.com/2007/07/20/actionscript-3-using-urlloader-to-send-and-load-server-variables/">Tushar Wadekar: ActionScript 3: Using URLLoader to send and load server variables</a><br /><a href="http://www.kirupa.com/forum/showthread.php?t=277069">Kirupa: String passed to URLVariables.decode() must be a URL-encoded query string&#8230;</a><br />StackOverflow: <a href="http://stackoverflow.com/questions/252915/how-to-send-array-throught-httpservice-in-adobe-flex-3">How to send array throught HTTPservice in Adobe Flex 3</a><br /><a href"http://groups.google.com/group/flex_india/browse_thread/thread/19d081e295905d28">Google Groups: Flex India Community: Flex to PHP variables array</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/actionscript/'>actionscript</a>, <a class='category' href='/blog/categories/flash/'>flash</a>, <a class='category' href='/blog/categories/flex/'>flex</a>, <a class='category' href='/blog/categories/programming/'>programming</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/21/how-do-you-populate-flex-spark-list/">How Do You Populate a Flex Spark List With Information From an Array?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-21T00:00:00-08:00" pubdate data-updated="true">Jan 21<span>st</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
First, you have to wrap the array up in a Collection class, and then you connect that Collection class to the Flex component.  Here&#8217;s my understanding of how the three of these things relate to each other in general:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/_SdPKamJbrgg/TToSbSYmLXI/AAAAAAAAAE4/qklhGy7hiRs/s1600/nuubu%2Bflex%2Bcomps.png" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="230" width="320" src="http://4.bp.blogspot.com/_SdPKamJbrgg/TToSbSYmLXI/AAAAAAAAAE4/qklhGy7hiRs/s320/nuubu%2Bflex%2Bcomps.png" /></a></div><br />In general, Collections also give you more functions to sort or filter arrays.  Also, if you alter the ArrayCollection &#8211; by adding or removing an item &#8211; you&#8217;ll affect the underlying array.<br /><br />In code, this is something that would (in general) work to link a List component to an array:<br /><br /><pre class="brush:cpp">&lt;?xml version="1.0" encoding="utf-8"?&gt;<br /><s:Application xmlns:fx="http://ns.adobe.com/mxml/2009" <br />      xmlns:s="library://ns.adobe.com/flex/spark" <br />      xmlns:mx="library://ns.adobe.com/flex/mx" minWidth="955" minHeight="600"><br /><br /> <fx:Script><br />  <![CDATA[<br />   import mx.collections.*;<br />   protected var array:Array;<br />   protected var arrayCollection:ArrayCollection = new ArrayCollection();<br /><br />   arrayCollection.source = array;<br />   list.dataProvider = arrayCollection;<br />  ]]><br /> </fx:Script><br /> <s:List x="642" y="183" id="list" height="200" width="100"></s:List><br /></s:Application><br /></pre><br /><br />Sources:<br /><a href="http://livedocs.adobe.com/flex/3/html/help.html?content=about_dataproviders_1.html">Adobe: Using Data Providers and Collections</a><br /><a href="http://livedocs.adobe.com/flex/3/html/help.html?content=dpcontrols_1.html#478370">Adobe: List control</a><br /><a href="http://blog.flexdevelopers.com/2009/03/flex-basics-arraycollection.html">Flex Developers & Development: ArrayCollection Basics</a><br /><a href="http://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/mx/collections/ArrayCollection.html">Adobe: ArrayCollection documentation</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/actionscript/'>actionscript</a>, <a class='category' href='/blog/categories/flash/'>flash</a>, <a class='category' href='/blog/categories/flex/'>flex</a>, <a class='category' href='/blog/categories/programming/'>programming</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/18/operating-systems-notes-chapter-6/">Operating Systems Notes [Chapter 6: Process Synchronization]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-18T00:00:00-08:00" pubdate data-updated="true">Jan 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So a <strong>cooperating process</strong> is one that can affect or be affected by other processes, because it shares address space (code, data) with other processes, or because it can share data through passing messages or files.  But, if you share data, then you can run into inconsistencies, i.e. if I&#8217;m reading a paper of numbers, adding them up, and halfway down while I&#8217;m reading it someone starts changing stuff.  By the time I get to the end of the paper, the answer that I get won&#8217;t properly reflect the sum of numbers that had originally been on the paper.<br /><br />The situation in which the outcome of the execution depends on the order of things that take place is a <strong>race condition</strong>.  So, the example earlier is a race condition, because the outcome will be different if I a) read and sum the paper, and then the paper gets rewritten, or if b) someone rewrites the paper, and then I read and sum the paper&#8217;s contents.<br /><br /><strong>Process synchronization</strong> concerns itself with making sure that the changes that result from different processes don&#8217;t interfere with what other processes are doing, even if they&#8217;re all sharing the same <strike>paper</strike> set of data.<br /><br />Parts of code to especially watch out for when trying to synchronize things are those parts that modify or write things, i.e. changing variables, outputting to file.  The part of a process which does this is called the <strong>critical section</strong> and to ensure consistency, you want to be sure you have critical sections which fulfill the following requirements:<ul><li><strong>mutual exclusion:</strong> only one thread is executing in the critical section at any time</li><li><strong>progress:</strong> if thread A and thread B are both outside of the critical section, neither can prevent the other from entering the critical section</li><li><strong>bounded waiting:</strong> (i.e. no starvation) if thread A is waiting to enter the critical section, it will enter it eventually</li><li><strong>performance:</strong> entering and exiting the critical section is small compared to the amount of work being done within it</li></ul><br />Critical sections can be built with <a href="http://nuubu.blogspot.com/2011/01/q-semaphore-mutex.html">semaphores and locks</a>, as well as monitors and messages.  Messages are when processes communicate to each other and have their synchronization taken care of through a communication layer; this is particularly important to <a href="http://nuubu.blogspot.com/2011/01/remote-procedure-calls-rpc.html">RPCs</a> in distributed systems.  Monitors are an abstract data structure which I talk more about below.<br /><br />Locks are the lowest-level mechanism you can use, and are really primitive.  Locks can be implemented either as spin-locks, which is when a process which needs a lock acquires it and goes; but if the lock is already posessed by another thread, the process will sit in a while loop, &#8220;spinning,&#8221; until the lock is free.  This is actually pretty bad because you&#8217;re using up CPU doing nothing, just&#8230;spinning around.<br /><br />You can also implement locks by disabling interrupts, and making sure that some process which is currently executing will not be interfered with by any other process.  But only the kernel should be able to disable interrupts, and if you have long periods of no interruptions then you can &#8220;wreak havoc&#8221; on certain devices.<br /><br />Both spinlocks and disabling interrupts should only be used to build higher-level constructs to ensure proper synchronization of processes.<br /><br /><br />Anyway, kernels can also run into race conditions.  For example, the kernel has a data structure that keeps track of all files that are presently open, and a race condition will occur if two processes open files simultaneously.  To handle critical sections in operating systems, there are <strong>preemptive kernels</strong> (which allow a process to be interrupted in kernel mode), and <strong>nonpreemptive kernels</strong> (which do not allow a process running in kernel mode to be preempted/interrupted, meaning a running kernel-mode process will run until it exits kernel mode).  Preemptive kernels, despite being prone to race conditions, are good for real-time programming scenarios, and are also more responsive since there&#8217;s less of a chance that you&#8217;ll have to wait for some arbitrary period until the processor is free to take on another process.<br /><br /><br /><span class="sig">Monitors</span><br />A monitor is an abstract data type which defines a set of operations which are allowed to be mutually exclusive.  It&#8217;s basically a class that allows shared private data, methods, and automatic synchronization.  A procedure defined in the monitor can only affect variables declared in the monitor, and variables defined in the monitor can only be accessed by functions in the monitor.  Within the monitor, only one process runs at a time.<br /><br />Monitors rely on a <strong>condition variable</strong>, which does three things:<ol><li><code>wait</code> &#8211; release a lock, wait for a signal, recapture a lock</li><li><code>signal</code> &#8211; wake up at most one thread which is waiting to access shared resource</li><li><code>broadcast</code> &#8211; wake up all waiting threads</li></ol>Monitors also manage queues of processes which are waiting to access the shared resource.<br /><br />A monitor can fix deadlocks in the dining philosophers problem.  A monitor would sit in the middle of the dining table, and the philosopher would first ask the monitor for forks.  The monitor would then make a couple of checks on the environment, see if there were any forks <strike>in the queue</strike> available, and if there is a good amount, then the monitor tell his pet condition construct, &#8220;Let the philosopher eat!&#8221;  The philosopher would then obtain forks, eat, and talk to the monitor again when he or she is done eating.<br /><br />There are two types of monitors: Hoare monitors, and Mesa monitors (the latter being the most prevalent today).  They differ in what action happens in the waiting queue after the condition variable signals.  In Hoare monitors, the waiting process is run immediately after <code>signal</code> is called, because it indicates that a resource that the process want has been freed.  In Mesa monitors, the signal doesn&#8217;t mean that a resource has been freed, rather only that something has changed.  Thus, when signal happens, the waiter is made ready to go, but only runs when the shared resource is completely for sure available.<br /><br />Unfortunately for monitors, they&#8217;re pretty heavyweight, so you can&#8217;t do any &#8220;fine-grained locking&#8221; &#8211; you have one thread in the monitor at a time, and that&#8217;s it.<br /><br /><br />Sources:<br /><em>Operating System Concepts (8th Edition)</em>, Silberschatz, Galvin and Gagne, ISBN 978-0-470-12872-5.<br /><a href="http://en.wikipedia.org/wiki/Atomicity">Wikipedia: Atomicity</a><br />lecture notes<br />section TA&#8217;s intensely well-designed slides</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/18/operating-systems-notes-chapter-5-cpu/">Operating Systems Notes [Chapter 5: CPU Scheduling]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-18T00:00:00-08:00" pubdate data-updated="true">Jan 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">Scheduling</span><br /><a href="http://nuubu.blogspot.com/2011/01/operating-system-notes-chapter-1.html">Recap</a>: <strong>multiprogramming</strong> takes advantage of the fact that no one process can keep the CPU busy at all times, so the CPU switches between different jobs so that it&#8217;s always busy executing something.  This makes the computer more productive in general.<br /><br />A process is comprised of an address space, OS resources, and <em>at least one thread of execution</em>, and it&#8217;s threads that get scheduled.  The operating system specifically schedules kernel-threads, which are threads of execution for programs that are part of the kernel.<br /><br />Scheduling is what a scheduler does.  Scheduling is concerned with two things:<ol><li>How long will the current process run on the CPU?</li><li>What process will get the CPU next?</li></ol><br />Actually, resources other than the CPU can be scheduled, like threads or devices or I/O access or pretty much everything else in a computer.  But, for now, just the CPU.<br /><br />Some challenges to scheduler design are<ul><li>There are new jobs all the time</li><li>How can you schedule a process when you&#8217;re not sure how long it will take to run completely?</li></ul><br /><br /><span class="sig">Process Cycles</span><br />Essential to scheduling is the idea that processes execute in a <strong>cycle</strong>, which is comprised of a <strong>CPU burst</strong> and an <strong>I/O burst</strong>, and then another CPU burst, and then another I/O burst, and so on until execution is terminated.<br /><br />During the CPU burst, the process is doing things like loading memory, incrementing variables, reading from file, writing to file, etc.  During the I/O burst, the process is just waiting for something (like input it needs to go on).  A program which depends a lot on I/O will have many short CPU bursts, whereas a program which is CPU-bound will have a few long CPU bursts.  CPU bursts vary hugely but tend to last around 1 or 2 milliseconds.  <span class="shh">Computers, you are amazing.</span><br /><br /><br /><span class="sig">Scheduling Schemes</span><br />The <strong>short-term scheduler</strong> (or CPU scheduler) decides, when the CPU becomes idle, what process to run from a list of processes which are ready to execute, and gives that process CPU.  The list of &#8220;ready&#8221; processes can be a queue, or a priority queue, or a tree, or a linked list, etc.<br /><br />Here&#8217;s a picture of the states of a process&#8217;s thread:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/_SdPKamJbrgg/TTZSV_VgYpI/AAAAAAAAAEs/lJ40rGVHVbo/s1600/states%2Bof%2Ba%2Bthread.jpg" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="285" width="320" src="http://4.bp.blogspot.com/_SdPKamJbrgg/TTZSV_VgYpI/AAAAAAAAAEs/lJ40rGVHVbo/s320/states%2Bof%2Ba%2Bthread.jpg" /></a></div><br /><br />The scheduler has two different types of schemes.<br /><br />In the <strong>nonpreemptive/cooperative</strong> scheduling scheme, once a process gets CPU allocated to it, the process keeps it until it terminates or goings into the waiting state.  It happens when <ul><li>a process goes from running to waiting state (i.e. because of an I/O request or when a child is being terminated)</li><li>a process terminates</li></ul><br /><strong>Preemptive</strong> scheduling is the opposite; if a process has CPU allocated to it, it still might be interrupted and have its resources allocated to another process.  Preemptive scheduling or nonpreemptive scheduling happens when<ul><li>a process switches from waiting to ready state (i.e. because completion of I/O)</li><li>a process goes from running state to ready state (i.e. because of an interrupt)</li></ul><br />In preemptive scheduling, since data is shared, you can run into concurrency problems where one of the processes sharing data alters it while others are reading it, giving everyone else different information then you may have intended them to have.<br /><br />Since interrupts can happen at any time, and since they can&#8217;t always be ignored by the kernel, code that can be affected by interrupts by be guarded from being used by something else, probably using mutexes, though the book doesn&#8217;t say that right now.<br /><br /><br /><span class="sig">Dispatcher</span><br />The dispatcher is what grants a process control to the CPU, once its been scheduled to have it.  The dispatcher takes care of switching context, switching to user mode, and jumping to the proper space in the user program to execute.<br /><br /><br /><span class="sig">Scheduling Criteria</span><br />Scheduling performance looks to do these things:<ul><li>CPU utilization: keep CPU has busy as possible</li><li>Throughput: make sure that the number of processes that are completed per unit of time is high (i.e. optimize so that 6 processes are completed per second)</li><li>Turnaround time: make sure that processes get completed fast</li><li>Waiting time: make sure that processes do not wait in the ready queue for a long time (and how long it takes a process to execute doesn&#8217;t matter)</li><li>Response time: make sure that processes&#8217; first output is fast (the ones following do as well; but response time refers to the time it takes for a process to give its first output)</li><li>Fairness: make sure that all the processes get a chance at using the resources</li><li>No starvation: make sure that no process never get a chance to run</li><li>Deadlines: make sure jobs finish by the time they need to</li><li>Thread locality: threads that are part of the same process run faster when they&#8217;re on the same processor (because they share memory), so it&#8217;s best to make sure this happens</li><li>etc: etc etc</li></ul><br />Obviously one algorithm can&#8217;t do all of these things though, so you&#8217;ll have to decide which algorithm is best for which kind of system.<br /><br /><br /><span class="sig">Scheduling Algorithms</span><br />All scheduling is concerned with is which of the processes in the ready queue should be allocated to the CPU.<br /><br />In <strong>first-come, first-served</strong> scheduling, the process that requests the CPU first gets the CPU first.  The ready queue in this case can be implemented as a FIFO queue.  The code is simple, but it&#8217;s slow.  One example of how it can be inefficient:<ol><li>In a ready queue, there&#8217;s one CPU-bound process, and many I/O-bound processes.</li><li>The CPU-bound process gets the CPU.  The I/O-bound processes wait.</li><li>The CPU-bound finishes, goes through its I/O burst.  With the CPU freed up, the I/O-bound processes use up the CPU for their CPU bursts &#8211; all quickly, since the CPU burst for an I/O-bound process is short &#8211; and then go back to the queue.</li><li>CPU is now idle, and eventually moved to the ready queue.  Once it gets the CPU, the other I/O-bound processes are left waiting again.</li></ol><br />This situation, where a lot of processes are waiting for one big processes to finish, is a <strong>convoy effect</strong>.  It means that the available CPU is lowered, and device utilization is poor.  Also, since a process that gets the CPU keeps it until the end, first-come first-serve scheduling is nonpreemptive.<br /><br /><br />In <strong>shortest-job-first scheduling</strong> (SJF), each process is associated with the length of its next CPU burst, and the process that gets chosen to have the CPU next is the one which has the smallest CPU burst.  This algorithm gives the minimum average waiting time for a given set of processes.  Disadvantage: it&#8217;s hard to know the length of the next CPU request.  Therefore, it&#8217;s best for long-term scheduling, when you can predict the length of a CPU burst since it will likely be close to the length of the CPU bursts before it.  The SJF algorithm is <em>optimal</em>, and can be either preemptive or nonpreemptive, where the difference is that the scheduler may allow interruptions to a currently running process.<br /><br /><br />The <strong>priority scheduling algorithm</strong> is a more general case of the SJF algorithm.  In this algorithm, each process is associated with a certain priority, and the processes with the greatest priority are chosen to run next.  Processes with equal priority are executed first-come, first-serve.  Priorities can be defined internally, in which case priority would be based on things like time limits or memory requirements.  Externally-defined processes would be set by criteria like whether the process is more important and stuff.<br /><br />Disadvantage: <strong>indefinite blocking</strong> or <strong>starvation</strong>, which can happen if some low-priority processes are kept waiting forever because there&#8217;s always someone more important to be resource-fed.  One solution: <strong>aging</strong>, which would increase the priority of a process the longer it&#8217;s been waiting.<br /><br /><br /><strong>Round-robin scheduling</strong> is especially for timesharing systems, and it&#8217;s like first-come first-serve scheduling but with preemption so that the system can switch between processes.  The ready queue is FIFO and circular, and the scheduler allocates CPU to each process, up to one unit of time, or a &#8220;time quantum.&#8221; Processes are chosen from the top of the ready queue and dispatched.  If the processes has a CPU burst of less than 1 time quantum, then it is allowed to continue; if not, then an interrupt will go off, and after having run for a quantum, that process will be placed at the tail of the ready queue.  This means: fairness, because all processes get a turn at the CPU, and also no starvation, because nothing will get ignored.<br /><br />Disadvantage: average waiting time if you&#8217;re going by RR scheduling is long, and the performance depends a lot on the size of the time quantum.  If it&#8217;s too large, than RR is the same as first-come first-serve; but if it&#8217;s too small, than it becomes like &#8220;processor sharing&#8221; and rather than each of n processes getting the whole CPU for a little bit, each process will get 1/nth of CPU.<br /><br /><br />In <strong>multilevel queue scheduling</strong>, processes are classified into different groups, i.e. <strong>foreground</strong> for interactive processes and <strong>background</strong> for batch processes, which have different scheduling needs.  In a multilevel queue schedule algorithm, the ready queue is split up into several separate queues and processes are assigned permanently to one queue based on some characteristic like process type or priority.  Each queue would have its own scheduling algorithm, and each queue would have its own priority, so that a lower-priority queue would be unable to execute anything until higher-priority queues are empty.<br /><br /><br /><br /><span class="sig">Thread Scheduling</span><br />Since we&#8217;re talking about the OS here, we&#8217;re talking about scheduling kernel-level threads, not user-level threads.  User-level threads are scheduled to run in a scheme using <strong>process-contention scope</strong>, where threads are chosen to run based on priority.  Kernel-threads are scheduled with <strong>system-contention scope</strong>.<br /><br /><br /><span class="sig">Other notes because I&#8217;m too lazy to finish this chapter in its entirety</span><br />If a system has multiple processors, usually each processor is allowed to schedule itself independently, with its own private queue of processes or threads.<br /><br /><br />Sources:<br /><em>Operating System Concepts (8th Edition)</em>, Silberschatz, Galvin and Gagne, ISBN 978-0-470-12872-5.<br />Class lecture 4 notes<br />Class section 3 notes</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/26/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/24/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About</h1>
  I&#8217;m Nadine. I like various things.  
</section>
<section>
  <h1>Other Places</h1>
  <ul>
    <li><a href="http://uxunicorn.com">Portfolio</a></li>
    <li><a href="http://neauro.tumblr.com">Tumblr</a></li>
    <li><a href="http://github.com/neauro">Github</a></li>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - nadine a. -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
