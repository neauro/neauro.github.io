
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>liwanag</title>
  <meta name="author" content="nadine a.">

  
  <meta name="description" content="Operating Systems Notes [Chapter 6: Process Synchronization] Jan 18th, 2011 So a cooperating process is one that can affect or be affected by other &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.neauro.com/blog/page/27">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="liwanag" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<link href="http://fonts.googleapis.com/css?family=Metrophobic:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-46467190-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">liwanag</a></h1>
  
    <h2>things i learn, things i like</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:blog.neauro.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/18/operating-systems-notes-chapter-6/">Operating Systems Notes [Chapter 6: Process Synchronization]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-18T00:00:00-08:00" pubdate data-updated="true">Jan 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So a <strong>cooperating process</strong> is one that can affect or be affected by other processes, because it shares address space (code, data) with other processes, or because it can share data through passing messages or files.  But, if you share data, then you can run into inconsistencies, i.e. if I&#8217;m reading a paper of numbers, adding them up, and halfway down while I&#8217;m reading it someone starts changing stuff.  By the time I get to the end of the paper, the answer that I get won&#8217;t properly reflect the sum of numbers that had originally been on the paper.<br /><br />The situation in which the outcome of the execution depends on the order of things that take place is a <strong>race condition</strong>.  So, the example earlier is a race condition, because the outcome will be different if I a) read and sum the paper, and then the paper gets rewritten, or if b) someone rewrites the paper, and then I read and sum the paper&#8217;s contents.<br /><br /><strong>Process synchronization</strong> concerns itself with making sure that the changes that result from different processes don&#8217;t interfere with what other processes are doing, even if they&#8217;re all sharing the same <strike>paper</strike> set of data.<br /><br />Parts of code to especially watch out for when trying to synchronize things are those parts that modify or write things, i.e. changing variables, outputting to file.  The part of a process which does this is called the <strong>critical section</strong> and to ensure consistency, you want to be sure you have critical sections which fulfill the following requirements:<ul><li><strong>mutual exclusion:</strong> only one thread is executing in the critical section at any time</li><li><strong>progress:</strong> if thread A and thread B are both outside of the critical section, neither can prevent the other from entering the critical section</li><li><strong>bounded waiting:</strong> (i.e. no starvation) if thread A is waiting to enter the critical section, it will enter it eventually</li><li><strong>performance:</strong> entering and exiting the critical section is small compared to the amount of work being done within it</li></ul><br />Critical sections can be built with <a href="http://nuubu.blogspot.com/2011/01/q-semaphore-mutex.html">semaphores and locks</a>, as well as monitors and messages.  Messages are when processes communicate to each other and have their synchronization taken care of through a communication layer; this is particularly important to <a href="http://nuubu.blogspot.com/2011/01/remote-procedure-calls-rpc.html">RPCs</a> in distributed systems.  Monitors are an abstract data structure which I talk more about below.<br /><br />Locks are the lowest-level mechanism you can use, and are really primitive.  Locks can be implemented either as spin-locks, which is when a process which needs a lock acquires it and goes; but if the lock is already posessed by another thread, the process will sit in a while loop, &#8220;spinning,&#8221; until the lock is free.  This is actually pretty bad because you&#8217;re using up CPU doing nothing, just&#8230;spinning around.<br /><br />You can also implement locks by disabling interrupts, and making sure that some process which is currently executing will not be interfered with by any other process.  But only the kernel should be able to disable interrupts, and if you have long periods of no interruptions then you can &#8220;wreak havoc&#8221; on certain devices.<br /><br />Both spinlocks and disabling interrupts should only be used to build higher-level constructs to ensure proper synchronization of processes.<br /><br /><br />Anyway, kernels can also run into race conditions.  For example, the kernel has a data structure that keeps track of all files that are presently open, and a race condition will occur if two processes open files simultaneously.  To handle critical sections in operating systems, there are <strong>preemptive kernels</strong> (which allow a process to be interrupted in kernel mode), and <strong>nonpreemptive kernels</strong> (which do not allow a process running in kernel mode to be preempted/interrupted, meaning a running kernel-mode process will run until it exits kernel mode).  Preemptive kernels, despite being prone to race conditions, are good for real-time programming scenarios, and are also more responsive since there&#8217;s less of a chance that you&#8217;ll have to wait for some arbitrary period until the processor is free to take on another process.<br /><br /><br /><span class="sig">Monitors</span><br />A monitor is an abstract data type which defines a set of operations which are allowed to be mutually exclusive.  It&#8217;s basically a class that allows shared private data, methods, and automatic synchronization.  A procedure defined in the monitor can only affect variables declared in the monitor, and variables defined in the monitor can only be accessed by functions in the monitor.  Within the monitor, only one process runs at a time.<br /><br />Monitors rely on a <strong>condition variable</strong>, which does three things:<ol><li><code>wait</code> &#8211; release a lock, wait for a signal, recapture a lock</li><li><code>signal</code> &#8211; wake up at most one thread which is waiting to access shared resource</li><li><code>broadcast</code> &#8211; wake up all waiting threads</li></ol>Monitors also manage queues of processes which are waiting to access the shared resource.<br /><br />A monitor can fix deadlocks in the dining philosophers problem.  A monitor would sit in the middle of the dining table, and the philosopher would first ask the monitor for forks.  The monitor would then make a couple of checks on the environment, see if there were any forks <strike>in the queue</strike> available, and if there is a good amount, then the monitor tell his pet condition construct, &#8220;Let the philosopher eat!&#8221;  The philosopher would then obtain forks, eat, and talk to the monitor again when he or she is done eating.<br /><br />There are two types of monitors: Hoare monitors, and Mesa monitors (the latter being the most prevalent today).  They differ in what action happens in the waiting queue after the condition variable signals.  In Hoare monitors, the waiting process is run immediately after <code>signal</code> is called, because it indicates that a resource that the process want has been freed.  In Mesa monitors, the signal doesn&#8217;t mean that a resource has been freed, rather only that something has changed.  Thus, when signal happens, the waiter is made ready to go, but only runs when the shared resource is completely for sure available.<br /><br />Unfortunately for monitors, they&#8217;re pretty heavyweight, so you can&#8217;t do any &#8220;fine-grained locking&#8221; &#8211; you have one thread in the monitor at a time, and that&#8217;s it.<br /><br /><br />Sources:<br /><em>Operating System Concepts (8th Edition)</em>, Silberschatz, Galvin and Gagne, ISBN 978-0-470-12872-5.<br /><a href="http://en.wikipedia.org/wiki/Atomicity">Wikipedia: Atomicity</a><br />lecture notes<br />section TA&#8217;s intensely well-designed slides</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/18/operating-systems-notes-chapter-5-cpu/">Operating Systems Notes [Chapter 5: CPU Scheduling]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-18T00:00:00-08:00" pubdate data-updated="true">Jan 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">Scheduling</span><br /><a href="http://nuubu.blogspot.com/2011/01/operating-system-notes-chapter-1.html">Recap</a>: <strong>multiprogramming</strong> takes advantage of the fact that no one process can keep the CPU busy at all times, so the CPU switches between different jobs so that it&#8217;s always busy executing something.  This makes the computer more productive in general.<br /><br />A process is comprised of an address space, OS resources, and <em>at least one thread of execution</em>, and it&#8217;s threads that get scheduled.  The operating system specifically schedules kernel-threads, which are threads of execution for programs that are part of the kernel.<br /><br />Scheduling is what a scheduler does.  Scheduling is concerned with two things:<ol><li>How long will the current process run on the CPU?</li><li>What process will get the CPU next?</li></ol><br />Actually, resources other than the CPU can be scheduled, like threads or devices or I/O access or pretty much everything else in a computer.  But, for now, just the CPU.<br /><br />Some challenges to scheduler design are<ul><li>There are new jobs all the time</li><li>How can you schedule a process when you&#8217;re not sure how long it will take to run completely?</li></ul><br /><br /><span class="sig">Process Cycles</span><br />Essential to scheduling is the idea that processes execute in a <strong>cycle</strong>, which is comprised of a <strong>CPU burst</strong> and an <strong>I/O burst</strong>, and then another CPU burst, and then another I/O burst, and so on until execution is terminated.<br /><br />During the CPU burst, the process is doing things like loading memory, incrementing variables, reading from file, writing to file, etc.  During the I/O burst, the process is just waiting for something (like input it needs to go on).  A program which depends a lot on I/O will have many short CPU bursts, whereas a program which is CPU-bound will have a few long CPU bursts.  CPU bursts vary hugely but tend to last around 1 or 2 milliseconds.  <span class="shh">Computers, you are amazing.</span><br /><br /><br /><span class="sig">Scheduling Schemes</span><br />The <strong>short-term scheduler</strong> (or CPU scheduler) decides, when the CPU becomes idle, what process to run from a list of processes which are ready to execute, and gives that process CPU.  The list of &#8220;ready&#8221; processes can be a queue, or a priority queue, or a tree, or a linked list, etc.<br /><br />Here&#8217;s a picture of the states of a process&#8217;s thread:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/_SdPKamJbrgg/TTZSV_VgYpI/AAAAAAAAAEs/lJ40rGVHVbo/s1600/states%2Bof%2Ba%2Bthread.jpg" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="285" width="320" src="http://4.bp.blogspot.com/_SdPKamJbrgg/TTZSV_VgYpI/AAAAAAAAAEs/lJ40rGVHVbo/s320/states%2Bof%2Ba%2Bthread.jpg" /></a></div><br /><br />The scheduler has two different types of schemes.<br /><br />In the <strong>nonpreemptive/cooperative</strong> scheduling scheme, once a process gets CPU allocated to it, the process keeps it until it terminates or goings into the waiting state.  It happens when <ul><li>a process goes from running to waiting state (i.e. because of an I/O request or when a child is being terminated)</li><li>a process terminates</li></ul><br /><strong>Preemptive</strong> scheduling is the opposite; if a process has CPU allocated to it, it still might be interrupted and have its resources allocated to another process.  Preemptive scheduling or nonpreemptive scheduling happens when<ul><li>a process switches from waiting to ready state (i.e. because completion of I/O)</li><li>a process goes from running state to ready state (i.e. because of an interrupt)</li></ul><br />In preemptive scheduling, since data is shared, you can run into concurrency problems where one of the processes sharing data alters it while others are reading it, giving everyone else different information then you may have intended them to have.<br /><br />Since interrupts can happen at any time, and since they can&#8217;t always be ignored by the kernel, code that can be affected by interrupts by be guarded from being used by something else, probably using mutexes, though the book doesn&#8217;t say that right now.<br /><br /><br /><span class="sig">Dispatcher</span><br />The dispatcher is what grants a process control to the CPU, once its been scheduled to have it.  The dispatcher takes care of switching context, switching to user mode, and jumping to the proper space in the user program to execute.<br /><br /><br /><span class="sig">Scheduling Criteria</span><br />Scheduling performance looks to do these things:<ul><li>CPU utilization: keep CPU has busy as possible</li><li>Throughput: make sure that the number of processes that are completed per unit of time is high (i.e. optimize so that 6 processes are completed per second)</li><li>Turnaround time: make sure that processes get completed fast</li><li>Waiting time: make sure that processes do not wait in the ready queue for a long time (and how long it takes a process to execute doesn&#8217;t matter)</li><li>Response time: make sure that processes&#8217; first output is fast (the ones following do as well; but response time refers to the time it takes for a process to give its first output)</li><li>Fairness: make sure that all the processes get a chance at using the resources</li><li>No starvation: make sure that no process never get a chance to run</li><li>Deadlines: make sure jobs finish by the time they need to</li><li>Thread locality: threads that are part of the same process run faster when they&#8217;re on the same processor (because they share memory), so it&#8217;s best to make sure this happens</li><li>etc: etc etc</li></ul><br />Obviously one algorithm can&#8217;t do all of these things though, so you&#8217;ll have to decide which algorithm is best for which kind of system.<br /><br /><br /><span class="sig">Scheduling Algorithms</span><br />All scheduling is concerned with is which of the processes in the ready queue should be allocated to the CPU.<br /><br />In <strong>first-come, first-served</strong> scheduling, the process that requests the CPU first gets the CPU first.  The ready queue in this case can be implemented as a FIFO queue.  The code is simple, but it&#8217;s slow.  One example of how it can be inefficient:<ol><li>In a ready queue, there&#8217;s one CPU-bound process, and many I/O-bound processes.</li><li>The CPU-bound process gets the CPU.  The I/O-bound processes wait.</li><li>The CPU-bound finishes, goes through its I/O burst.  With the CPU freed up, the I/O-bound processes use up the CPU for their CPU bursts &#8211; all quickly, since the CPU burst for an I/O-bound process is short &#8211; and then go back to the queue.</li><li>CPU is now idle, and eventually moved to the ready queue.  Once it gets the CPU, the other I/O-bound processes are left waiting again.</li></ol><br />This situation, where a lot of processes are waiting for one big processes to finish, is a <strong>convoy effect</strong>.  It means that the available CPU is lowered, and device utilization is poor.  Also, since a process that gets the CPU keeps it until the end, first-come first-serve scheduling is nonpreemptive.<br /><br /><br />In <strong>shortest-job-first scheduling</strong> (SJF), each process is associated with the length of its next CPU burst, and the process that gets chosen to have the CPU next is the one which has the smallest CPU burst.  This algorithm gives the minimum average waiting time for a given set of processes.  Disadvantage: it&#8217;s hard to know the length of the next CPU request.  Therefore, it&#8217;s best for long-term scheduling, when you can predict the length of a CPU burst since it will likely be close to the length of the CPU bursts before it.  The SJF algorithm is <em>optimal</em>, and can be either preemptive or nonpreemptive, where the difference is that the scheduler may allow interruptions to a currently running process.<br /><br /><br />The <strong>priority scheduling algorithm</strong> is a more general case of the SJF algorithm.  In this algorithm, each process is associated with a certain priority, and the processes with the greatest priority are chosen to run next.  Processes with equal priority are executed first-come, first-serve.  Priorities can be defined internally, in which case priority would be based on things like time limits or memory requirements.  Externally-defined processes would be set by criteria like whether the process is more important and stuff.<br /><br />Disadvantage: <strong>indefinite blocking</strong> or <strong>starvation</strong>, which can happen if some low-priority processes are kept waiting forever because there&#8217;s always someone more important to be resource-fed.  One solution: <strong>aging</strong>, which would increase the priority of a process the longer it&#8217;s been waiting.<br /><br /><br /><strong>Round-robin scheduling</strong> is especially for timesharing systems, and it&#8217;s like first-come first-serve scheduling but with preemption so that the system can switch between processes.  The ready queue is FIFO and circular, and the scheduler allocates CPU to each process, up to one unit of time, or a &#8220;time quantum.&#8221; Processes are chosen from the top of the ready queue and dispatched.  If the processes has a CPU burst of less than 1 time quantum, then it is allowed to continue; if not, then an interrupt will go off, and after having run for a quantum, that process will be placed at the tail of the ready queue.  This means: fairness, because all processes get a turn at the CPU, and also no starvation, because nothing will get ignored.<br /><br />Disadvantage: average waiting time if you&#8217;re going by RR scheduling is long, and the performance depends a lot on the size of the time quantum.  If it&#8217;s too large, than RR is the same as first-come first-serve; but if it&#8217;s too small, than it becomes like &#8220;processor sharing&#8221; and rather than each of n processes getting the whole CPU for a little bit, each process will get 1/nth of CPU.<br /><br /><br />In <strong>multilevel queue scheduling</strong>, processes are classified into different groups, i.e. <strong>foreground</strong> for interactive processes and <strong>background</strong> for batch processes, which have different scheduling needs.  In a multilevel queue schedule algorithm, the ready queue is split up into several separate queues and processes are assigned permanently to one queue based on some characteristic like process type or priority.  Each queue would have its own scheduling algorithm, and each queue would have its own priority, so that a lower-priority queue would be unable to execute anything until higher-priority queues are empty.<br /><br /><br /><br /><span class="sig">Thread Scheduling</span><br />Since we&#8217;re talking about the OS here, we&#8217;re talking about scheduling kernel-level threads, not user-level threads.  User-level threads are scheduled to run in a scheme using <strong>process-contention scope</strong>, where threads are chosen to run based on priority.  Kernel-threads are scheduled with <strong>system-contention scope</strong>.<br /><br /><br /><span class="sig">Other notes because I&#8217;m too lazy to finish this chapter in its entirety</span><br />If a system has multiple processors, usually each processor is allowed to schedule itself independently, with its own private queue of processes or threads.<br /><br /><br />Sources:<br /><em>Operating System Concepts (8th Edition)</em>, Silberschatz, Galvin and Gagne, ISBN 978-0-470-12872-5.<br />Class lecture 4 notes<br />Class section 3 notes</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/18/last-night-andou-asked-me-if-you/">Last Night Andou Asked Me, if You Started Writing a Book Right Now, What Would It Be About?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-18T00:00:00-08:00" pubdate data-updated="true">Jan 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">That morning at the last stop, when Sara unzipped her lunchbox to trade her mother&#8217;s lasagna (secretly full of vegetables) for a bag of chips, a man walked onto the school bus, shot the bus driver, kicked his body out the door, and took the steering wheel.</span></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/drabble/'>drabble</a>, <a class='category' href='/blog/categories/writing/'>writing</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/16/q-standard-annotation-language-sal/">[Q&a] Standard Annotation Language (SAL)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-16T00:00:00-08:00" pubdate data-updated="true">Jan 16<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">What does <code>__inout</code>, etc. mean?</span><br />For OS I&#8217;m plumbing the depths of a Windows kernel and keep running into these things in the code that look like <code>__in</code>, or <code>__out</code>, or even <code>__inout</code>&#8230;for example:<br /><br /><pre class="brush:xml">NTKERNELAPI<br />VOID<br />FASTCALL<br />ExAcquireFastMutexUnsafe (<br />    __inout PFAST_MUTEX FastMutex<br />    );<br /></pre><br />I initially found <a href="http://nuubu.blogspot.com/2011/01/q-operating-systems-etc.html">something</a> about the usage of <code>_</code> and <code>__</code> in code, and it turns out that <code>__</code> is just an annotation which will help programmers know more about the intended usage of the code, like comments, and are ignored by the compiler.  <code>__inout</code> stuff is no different.<br /><br />These annotations are part of Microsoft&#8217;s SAL, or, Standard Annotation Language, and define the proper use of buffers, which are regions of data that have been allocated and are represented as pointers.  If a pointer is pointing to a buffer, there&#8217;s no good way to know how big a buffer is in compile time; with usage of SAL, you can make explicit exactly how big a buffer is.  It also helps to show how a function uses its parameters &#8211; what it thinks that the parameter is, and what it will do with that parameter when it finishes.<br /><br />This is relevant because in C, a function can take a value or a pointer as an argument.  Arguments can be used as input (i.e. taking values to add together), or as output (i.e. taking a pointer to something which will store your output value.) But, if you were to leave out these annotations, you wouldn&#8217;t know if an argument a function takes is supposed to be used as function input or output.<br /><br /><code>__in</code>, <code>__out</code>, and <code>__inout</code> are all examples of &#8220;Usage&#8221; annotations.<br /><br />So, if you see something like<br /><br /><pre class="brush: xml">void * memset(<br /> __out_bcount(s) char *p,<br /> __in int v, <br /> __in size_t s);<br /></pre><br />This means that the function <code>memset</code> expects variables <code>int v</code> and <code>size_t s</code> to be valid when the function is called (also called &#8220;valid on input&#8221;).  Also, the buffer <code>char *p</code> will be initialized by this function, will be written to by this function, and will be valid when the function returns.<br /><br />In simpler terms &#8211; <code>v</code> and <code>s</code> are definitely meant to be <code>memset</code>&#8217;s input, and <code>p</code> is meant to be the output.<br /><br /><br />Sources:<br /><a href="http://207.46.16.248/en-us/library/ff550230%28VS.85%29.aspx">MSDN: Overview of Annotations for Drivers</a><br /><a href="http://msdn.microsoft.com/en-us/library/ms235402%28v=vs.80%29.aspx">MSDN: SAL Annotations</a><br /><a href="http://blogs.msdn.com/b/michael_howard/archive/2006/05/19/602077.aspx">MSDN: A Brief Introduction to the Standard Annotation Language</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/c/'>c</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>, <a class='category' href='/blog/categories/programming/'>programming</a>, <a class='category' href='/blog/categories/qna/'>qna</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/14/q-semaphore-mutex/">[Q&a] Semaphore, Mutex</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-14T00:00:00-08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">What&#8217;s a semaphore?</span><br />A semaphore is a procted variable or abstract data type.  It relates to controlling access to some resource shared by processes running simultaneously.  They&#8217;re useful in preventing race conditions and deadlocks (though they don&#8217;t prevent them completely).<br /><br />Semaphores don&#8217;t keep track of which resources are free or who is using the resources; they only keep track of whether resources are free.  There are two types of semaphores: <b>counting semaphores</b> and <b>binary semaphores</b>.  Counting semaphores only keep track of how much of the resource is available at a given time (i.e. &#8220;all of my resources are being used up now&#8230;oh, someone came back, okay, now I have one free which you can use&#8221;).  Binary semaphores only keep track of whether a resource is being used or not, i.e. whether it is presently unavailable or available.<br /><br />Semaphores can&#8217;t prevent errors that occur if a process that has acquired a lock for the resource forgets to release the lock, etc.<br /><br />Also, errors can still happen if there are different resources managed by different semaphores and processes need to use more than one resource at a time.  An interesting thing: the <a href="http://en.wikipedia.org/wiki/Dining_philosophers_problem">dining philosophers problem</a>, which illustrates the problems with multiple processes sharing multiple resources.  Essentially, five philosophers are sitting at a table, either eating or thinking.  They each have a fork to their left and right, and there is a bowl of spaghetti in the middle of the table.  The philosophers need to serve themselves and eat spaghetti with both forks, but don&#8217;t speak to each other, so one may pick up a left fork and wait for his right fork to become free so that he may eat.  Meanwhile, the guy using his right fork may be waiting for his own other fork to become free.  And so on, and so forth.<br /><br />A semaphore in this case would be like a person who is aware of which forks are being used and which ones are available, so that when the philosophers try to eat, they have to consult him first, and he&#8217;ll tell them whether there are any forks to pick up which they can use.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TS9WBJzlB7I/AAAAAAAAAEk/QEHATD_NLWw/s1600/proceed%2Bcat.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="283" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TS9WBJzlB7I/AAAAAAAAAEk/QEHATD_NLWw/s320/proceed%2Bcat.jpg" width="300" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">semaphore cat is semaphore</td></tr></tbody></table><br />One problem with semaphores: <strong>busy waiting</strong>, which is what you need to put into processes that are waiting for other processes to finish executing their critical section.  (Or, what philosophers are doing when they are waiting for their neighbors to finish eating.) The busy waiting is basically just a loop waiting for the mutex to free up, and it wastes CPU that another process could be productive with.  A process that does this is a <strong>spinlock</strong>, because &#8220;the process &#8216;spins&#8217; while waiting for the lock.&#8221;  Essentially, if a program knows it needs a lock before it does the next bit of code, it sits in a while loop until the needed lock is freed up.<br /><br /><br /><span class="sig">What&#8217;s a mutex?</span><br />A mutex is essentially a binary semaphore, though mutex specifically describes an abstraction which prevents two processes from executing the same piece of code or accessing the same data at the same time.  Basically, it limits access to a single resource, to one &#8220;owner&#8221; who is at that time allowed to do whatever it wants with it before releasing the mutex so someone else can do something.<br /><br /><br /><span class="sig">What does IRQL mean?</span><br />IRQL stands for Interrupt Request Level, and has something to do with a process, and, given incoming interrupts, which one of those interrupts should be able to interrupt the running process, and which should not.  For instance, if you&#8217;re just quickly trying to modify a single variable, then you don&#8217;t want anything to interrupt you.<br /><br />Basically (I think), each thread has its own IRQL.  If the OS receives another thread to run which has a higher IRQL than that first thread, however, then it will pause the lower-IRQL thread to run the higher-IRQL code.  Weird deadlocks may occur in this case, however, if:<br /><ol><li>lower-IRQL thread is running, and acquires a lock</li><li>lower-IRQL thread is interrupted; higher-IRQL thread begins execution</li><li>higher-IRQL thread needs the lock that lower-IRQL thread has</li><li>higher-IRQL lock cannot continue without that lock</li><li>lower-IRQL thread cannot continue without higher-IRQL finishing execution</li></ol>So, what you would want to do in this case is make sure that a thread that obtains a lock cannot be interrupted.<br /><br />If it does so happen that you don&#8217;t want any interrupts to your thread, then make sure that the IRQL is raised to <code>APC_LEVEL</code>.  This level is pretty much only run when you&#8217;re using Fast Mutexes.  Part of the reason why Fast Mutexes are faster than normal Mutexes in the Windows kernel is because they deny APC interrupts.  APC interrupts originate from the processor, toward itself or another processor.<br /><br /><br /><span class="sig">How do I use a mutex in the Windows NT kernel?</span><br /><a href="http://www-user.tu-chemnitz.de/~heha/oney_wdm/ch04f.htm">Here&#8217;s</a> a start&#8230;<br /><br /><br />Sources:<br /><a href="http://en.wikipedia.org/wiki/Semaphore_%28programming%29">Wikipedia: Semaphore (programming)</a><br /><a href="http://us.generation-nt.com/answer/fast-mutexes-guarded-mutexes-help-27627542.html">GNT: Fast mutexes and guarded mutexes?</a><br /><a href="http://blogs.technet.com/b/askperf/archive/2009/07/21/the-basics-of-mutexes-and-spin-locks.aspx">TechNet: The Basics of Mutexes and Spin Locks</a><br /><a href="http://blogs.msdn.com/b/doronh/archive/2010/02/02/what-is-irql.aspx">MSDN: What is IRQL?</a><br /><a href="http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBMQFjAA&amp;url=http%3A%2F%2Fdownload.microsoft.com%2Fdownload%2Fe%2Fb%2Fa%2Feba1050f-a31d-436b-9281-92cdfeae4b45%2FLocks.doc&amp;rct=j&amp;q=ex%20initialize%20fast%20mutex%20example&amp;ei=yJEzTf7ILIGqsAP4rqiFBg&amp;usg=AFQjCNEWYt0oNPRzKd8sXHFsm_CgrHKZBw&amp;sig2=4FQ-QHdGlj_42VPdrKqIxA&amp;cad=rja">Windows Hardware and Driver Central: Locks, Deadlocks, and Synchronization</a><br /><em>Operating System Concepts (8th Edition)</em>, Silberschatz, Galvin and Gagne, ISBN 978-0-470-12872-5.</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/qna/'>qna</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/14/operating-systems-notes-chapter-2-3/">Operating Systems Notes [Chapter 2, 3]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-14T00:00:00-08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">OS Structures</span><br /><strong>Command shells</strong>, I guess, make it so that users can actually speak directly to the OS and do something, rather than writing a program to speak with the OS.  I didn&#8217;t realize this.<br /><br />To make requests of the OS otherwise, you&#8217;d need to do a <strong>system call</strong>.  Types of requests that you might make the the OS would involve process control, and file and device manipulation (i.e. writing, reading from a mouse or file).<br /><br />Since operating systems are huge and all its parts tend to be interconnected, some better ways to program them involve using <strong>layers</strong> or <strong>microkernels</strong>.<br /><br />In the layered system, the OS structure is broken into layers, with the lowest being hardware and the highest being the user interface.  Layers can speak to adjacent layers, but not further.  The advantage is that you could be working on one layer at a time, and assume that if it works that you can move on to the next layer.  The issue with this is that you make the assumption that layers would not need to have communication across layers, when really sometimes layers <em>do</em> need to speak across other layers in real life, i.e. a user program needing to alter a file.<br /><br />In a microkernel system, all non-essential kernel programs are implemented as system and user-level programs, which means that the kernel is as small as it can possibly be to code it.  In general, this minimal kernel would provide only process and memory management along with a way to communicate.  The main function of the microkernel now is only to facilitate communication between the client program and other services, with messages.  Advantage is that it&#8217;s also easy to extend a microkernel&#8217;s functionality.  Disadvantage: poor performance if you need to make tons of system calls.<br /><br />In general, modularity is important.<br /><br /><br /><span class="sig">Processes</span><br />A process is a program in execution.  It consists of an address space, at least one thread, and a set of OS resources.  The address space is memory which contains code and data for the running program, as well as data relevant to the threads: registers, instruction pointer, stack and stack pointer.  A process also has a set of OS resources, such as open files, network connections, etc.  A process contains everything you need to run the program, or to restart it, if it gets interrupted.<br /><br />Processes may be independent or cooperating, depending on how they interact with each other.  <strong>Cooperating processes</strong> require some way to communicate with each other: either through shared memory (through shared variables), or message passing (through a pipe).  With shared memory, application programmers manage the communication, whereas with message-passing, the operating system has to take care of communication.  Shared memory and message passing aren&#8217;t mutually exclusive.<br /><br />You can also communicate across computers in a client-server system using sockets, remote procedure calls, or pipes.  A socket is an endpoint for communication, so a connection between two applications consists of two sockets, one for each.  <a href="http://nuubu.blogspot.com/2011/01/remote-procedure-calls-rpc.html">Remote procedure calls</a> are when an application calls another application&#8217;s function across a system.  Pipes come in two flavors: ordinary, which allows parent and child processes to communicate; and named, which allows two unrelated processes to speak with each other.</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/14/flexas3-errors-with-stage-and-event/">Flex/AS3: Errors With Stage and Event Listeners</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-14T00:00:00-08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
This is a continuation of myself attempting to find out how to <a href="http://nuubu.blogspot.com/2010/12/problem-how-do-i-use-flex-components-to.html">use Flex UI components with a previously created AS3 project</a>.<br /><br />And it works fine, except for this error which I get when running in debug mode:<br /><br /><code>TypeError: Error #1009: Cannot access a property or method of a null object reference.</code><br /><br />It turns out that this error refers to a part of the AS3 code which does something with this variable called the stage.  This stage variable was an instance of the <strong>Stage</strong> class, and it&#8217;s made when the Flash Player starts.  SWF files are loaded into the stage container, and all of their objects that display are DisplayObjects, and are children of the stage.  All DisplayObject instances also have a <code>stage</code> property which references the stage that is displaying them.  <span class="shh">Also: Stage is a singleton class, meaning there&#8217;s only one of them, and it can&#8217;t be modified by lowly programmers, and is always at the top level of the display hierarchy within a Flash Player.</span><br /><br />Anyway, the error occurs (I think) because my parent (UI) application loads onto the stage before the embedded (AS3) application.  The AS3 app then tries to use the <code>stage</code> property before it&#8217;s even on the stage.  The solution is to make sure that the embedded SWF is on the stage before you try instantiating or doing anything.<br /><br />To fix it, I essentially wrapped up offending code in an event listener which would wait until the stage was loaded to execute.  So, this code which lets the stage listen for keyboard input:<br /><br /><pre class="brush: cpp"><br />stage.addEventListener(KeyboardEvent.KEY_DOWN, keyDownHandler);<br /><br /></pre><br />became<br /><br /><pre class="brush: cpp"><br />addEventListener(Event.ADDED_TO_STAGE, function (e:Event):void {<br />  stage.addEventListener(KeyboardEvent.KEY_DOWN, keyDownHandler);<br />});<br /><br /></pre><br />Not sure if this is good style or not.<br /><br /><br />Sources:<br /><a href="http://www.kirupa.com/forum/showthread.php?p=2129548#post2129548">Kirupa: ActionScript 3 Tip of the Day</a><br /><a href="http://jaycsantos.com/flash/do-you-know-actionscript-as3-stage/">jaycsantos.com: Do you know ActionScript?  AS3 Stage</a><br /><a href="http://board.flashkit.com/board/showthread.php?t=792605">Flash Kit: TypeError: Error #1009</a></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Lewis R Strasburg</div>
<div class='content'>
Nice solution, it worked great for me.  I only needed to reference the stage at the very beginning for a &quot;Press Any Key to Start&quot; scenario, and it wasn&#39;t working until now.  Thanks!</div>
</div>
</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/actionscript/'>actionscript</a>, <a class='category' href='/blog/categories/flash/'>flash</a>, <a class='category' href='/blog/categories/flex/'>flex</a>, <a class='category' href='/blog/categories/troubleshooting/'>troubleshooting</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/09/c-typedef-struct/">C: Typedef, Struct, Extern</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-09T00:00:00-08:00" pubdate data-updated="true">Jan 9<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">What is <code>typedef</code> and <code>struct</code>?</span><br />A struct in C is a structured type that combines a set of labeled objects of different types, into a single object.  So, kind of like a Java object with its own variables.<br /><br />An example of a struct you could make would be<br /><br /><pre class="brush: cpp">struct pokemon {<br />   char* nickname;<br />   char* species;<br />   int level;<br />   char* item;<br />};<br /></pre><br />Then, to create a new Pokemon struct, I could say<br /><br /><pre class="brush: cpp">struct Pokemon pikachu;<br /></pre><br />And to access the new struct&#8217;s nickname, I could say something like<br /><br /><pre class="brush: cpp">pikachu.nickname;<br /></pre><br />The keyword <code>typedef</code> is just meant so that you can assign different &#8220;names&#8221; to existing types, in case you may get confused.  For instance, you might have code that looks like<br /><br /><pre class="brush: cpp">char* pokemon_name;<br />char* item;<br /><br />void buy(char* item) {<br />   // remove money from the user<br />}<br /></pre><br />Though <code>buy</code> can take any char*, what you really want it to do is only accept char* that represent items, not Pokemon nicknames.  So, you can use typedef to distinguish that pokemon_name and item are completely unrelated variables which happen to both be of type char*.<br /><br /><pre class="brush: cpp">typedef char* pokemon_name;<br />typedef char* item;<br /><br />pokemon_name pokemon_nickname;<br />item item_name;<br /><br />void buy(char* item) {<br />   // remove money from the user<br />}<br /></pre><br />This distinction is only for the programmer; the C/C++ compiler considers both things to be char*, and won&#8217;t give any errors if you happen to try and purchase a Pokemon.  <span class="shh">You cheat.</span><br /><br /><code>typedef</code> can also make declarations easier; for instance, if I did something like<br /><br /><pre class="brush:cpp">typedef struct Pokemon {<br />   char* nickname;<br />   char* species;<br />   int level;<br />   char* item;<br />} Pokemon;<br /></pre><br />Then, instead of having to write <code>struct Pokemon pikachu;</code> like earlier, I could make a new Pokemon just by saying<br /><br /><pre class="brush: cpp">Pokemon pikachu;<br /></pre><br /><br /><span class="sig">What does <code>extern</code> mean?</span><br />The <code>extern</code> declaration indicates the existence of, and type of, a global variable or function.  <code>extern</code> means that something is defined externally to the current module (so if your current .c file is using it, that means that another, included file actually defined it?).  <code>extern</code> can be left off because the linker collapses the multiple definitions into a single one, but to use the <code>extern</code> keyword is cleaner because it defines the global variable in one place, and everything else makes <code>extern</code> references to it.  <br /><br />If a program has a variable that&#8217;s declared as <code>extern</code>, the program won&#8217;t reserve any memory for the variable in the scope that it was declared.  Which is why you need to use the <code>extern</code> keyword in programs that are using the declaration, but haven&#8217;t defined it.<br /><br /><br /><br />Source:<br /><a href="http://en.wikipedia.org/wiki/Struct_%28C_programming_language%29">Wikipedia: Struct (C programming language)</a><br /><a href="http://wiki.answers.com/Q/What_is_the_use_of_extern_in_C">Answers.com: What is the use of extern in C</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/c/'>c</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/programming/'>programming</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/06/q-operating-systems-etc/">[Q&a] Operating Systems, C, Etc.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-06T00:00:00-08:00" pubdate data-updated="true">Jan 6<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<b>How do you switch drives with Windows command line?</b><br />If you want to go to drive <code>Z:</code>, rather than <code>cd Z:</code>, you can just type <code>Z:</code>.<br /><br /><br /><b>What do you do when you demux something?</b><br />A demultiplexer is a device that takes a single input signal and routes it to one of many output lines.  It&#8217;s often used with a multiplexer on the sending end.  So, when you demux a signal, you accept it, and then based on some parameter send it to a different function or something. <span class="shh">I think?</span><br /><br /><br /><b>What&#8217;s a virtual machine?</b><br />&#8220;A software implementation of a programmable machine&#8221; &#8211; so, a simulation of a computer, on a computer.<br /><br /><br /><b>What&#8217;s the difference between a function in C and a method in Java?</b><br />All C/C++ programs require a function named <code>main</code> and besides that can have numerous other functions.  In Java, functions can&#8217;t stand by themselves &#8211; they have to be part of a class.  Functions that are part of a class are usually called methods.<br /><br />Also, it seems that methods are called by reference values, which are objects, perhaps like <code>Object.method()</code>, as opposed to just <code>value = function()</code>?  Also, &#8220;method&#8221; is used more often in Java, most likely because Java has objects and C/C++ does not.<br /><br /><br /><b>What&#8217;s Windows NT?</b><br />It&#8217;s a family of operating systems created by Microsoft, which were meant to complement consumer versions of Windows that were based on MS-DOS.  NT was the first fully 32-bit version of Windows.  Windows 2000, Windows XP, Windows Server 2003, Windows Vista, Windows 7, etc., are based on Windows NT, though they aren&#8217;t branded the same way.  NT was once expanded to mean &#8220;New Technology&#8221; and stood originally for &#8220;N-Ten,&#8221; the codename of the Intell i860 XR processor that the OS was originally developed for, but NT has no particular meaning anymore.  Sidenote: it is really confusing that there&#8217;s an operating system called Windows <i>Server</i> 2003.  <i>Wat.</i>  I guess this calls into question what exactly a server is supposed to be.<br /><br /><br /><b>What is a server?</b><br />A server can refer to:<br /><ul><li>a computer program running as <a href="http://nuubu.blogspot.com/2011/01/intro-to-distributed-systems.html">a service</a>, to serve the needs or requests of other programs</li><li>a physical computer running one or more such services, to serve the needs of programs running on other computers in the same network</li><li>a software/hardware system such as a database server, file server, mail server, print server</li></ul>I guess server operating systems are operating systems that have certain features which make them good servers &#8211; such as limited GUI, flexible/advanced networking capability, tight security, backup securities, transparent data transfer between different volumes or devices &#8211; and maybe that&#8217;s what the Windows Server operating systems are all about.<br /><br /><br /><b>How do you press Ctrl+Alt+Delete in a virtual machine?</b><br />In a virtual machine in MS Virtual PC 2007, rather than pressing the keys, go to the <code>Action</code> tab and select <code>Ctrl+Alt+Delete</code>.<br /><br /><br /><b>What does the <code>_</code> or <code>__</code> mean in C programs?</b><br />There&#8217;s no particular meaning.  <code>_</code> is meant to identify system variables/functions, <code>__</code> is meant to identify metadata.  Additionally, when you include headers in C, you <br />add in a lot of code and functions and variables; to prevent these imported names from causing duplicates with the variables/names of your own stuff, it&#8217;s best to avoid using variables/functions which start with underscores in your own program.<br /><br /><br /><br /><br />Source:<br />Jimmy<br />Wikipedia: <a href="http://en.wikipedia.org/wiki/Multiplexer">1</a>, <a href="http://en.wikipedia.org/wiki/Virtual_machine">2</a>, <a href="http://en.wikipedia.org/wiki/Windows_NT">3</a>, <a href="http://en.wikipedia.org/wiki/Server_%28computing%29">4</a><br /><a href="http://www.geekinterview.com/question_details/31163">GeekInterview: What is the difference between methods and functions?</a><br /><a href="http://www.dickbaldwin.com/java/Java008.htm">Dick Baldwin: Similarities and Differences between Java and C++</a><br /><a href="http://bytes.com/topic/c/answers/540408-_-__-significance">Bytes: _ and __ significance</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/c/'>c</a>, <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/qna/'>qna</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/01/06/operating-systems-notes-lecture-2/">Operating Systems Notes [Lecture 2]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-01-06T00:00:00-08:00" pubdate data-updated="true">Jan 6<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
An operating system provides <a href="http://nuubu.blogspot.com/2011/01/operating-system-notes-chapter-1.html">a middle ground</a> between hardware and software, so making an operating system depends a lot on what hardware you have underlying it.  Computer hardware, however, has the amazing capacity to (at least until fairly recently) follow <strong>Moore&#8217;s Law</strong>, which states that <em>the number of transistors that can be placed inexpensively on an integrated circuit has doubled approximately every two years.</em>  I guess this trend has persisted for half a century, making it so that processors and memory have become ridiculously cheap, ridiculously fast.<br /><br />What this means is, the hardware conditions that you assume and initially create your operating system for may not hold true, and then you&#8217;ll be screwed.<br /><br />One interesting thing is that, though processor performance has increased throughout the years, disk capacity has become 10x as fast as processor performance.  Disk performance has <em>not</em> kept up, having only increased by a factor of 200 since 1983 (from 500 kb/s to ~100 mb/s).  Bandwidth presently is 100x as fast as processor performance, and 10x as fast as disk performance.<br /><br />An obvious implication of these unexpected growths is this: What happens if you have always designed systems so that they spend processing power so as to save &#8220;scarce&#8221; storage and bandwidth?<br /><br />Another thing: operating systems must load programs into main memory in order to execute them, but main memory is not large enough to hold everything all at once, and occasionally you&#8217;ll have to fetch data from the disc.  A computer going out of its way to fetch data from the disc is like a human going out of its way to fetch something from Pluto.  <em>Uphill.  Both ways.  In space.</em><br /><br />In general, hardware can dictate a lot about how simple or complex it will be to implement an OS.  Early OS (like DOS) didn&#8217;t have virtual memory, because the hardware didn&#8217;t allow it; and until recently, Intel-based PCs still didn&#8217;t support 64-bit addressing, though other platforms have had it since forever, like IBM, MIPS, etc.<br /><br />Features were also sometimes built into hardware to support OS building, like timer operation, memory protection, interrupts and exceptions, system calls.<br /><br /><strong>System calls</strong> are there so that the user can call an OS procedure, which is otherwise protected and kept out of hand&#8217;s reach on top of the refridgerator in kernel mode, so that the user doesn&#8217;t eat it all and spill it all over everything.  Once the user is done having a dessert cookie, the OS moves back into user mode, and relinquishes control back to the user.<br /><br />The kernel must save the state that the user was in before the user wanted to eat a cookie, so that it can remember what it was doing before it was interrupted, and resume.<br /><br />So in general the OS sits around waiting for events to happen that it can deal with.  Events can be interrupts, which are sent by programs, or they can be exceptions.  <strong>Exceptions</strong> are thrown by hardware once it detects certain rules being violated (like if someone tries to write to a read-only file), and when they happen control must be passed to the OS&#8217;s handler, with the saved state at the time of the fault.  Exceptions are a performance optimization in that the OS doesn&#8217;t have to deal with figuring out when things are going wrong &#8211; the hardware detects the violation &#8211; and detecting exceptions would be a big hassle for the OS because those extra checks would have to be written into the kernel, taking valuable space.<br /><br />In the meantime, interrupts allow for <strong>asynchronous I/O</strong>.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TSasz1jh5fI/AAAAAAAAAD8/9lBMBA1S9E0/s1600/os%2Bio%2Bcontrol.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="320" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TSasz1jh5fI/AAAAAAAAAD8/9lBMBA1S9E0/s320/os%2Bio%2Bcontrol.jpg" width="246" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">this is how we deal with I/O interrupts around here</td></tr></tbody></table><br />So, I/O interrupts can happen at any time, any place.  How do you protect yourself from getting interrupted so much that you end up never getting anything done?  Your OS will have to be able to <strong>synchronize concurrent processes</strong> by guaranteeing that short instructions (read-modify-write) will happen automatically; or maybe, by not letting certain processes get interrupted until their finished; or maybe, by having special atomic instructions, such as the read-modify-write, which you execute immediately.<br /><br /><strong>Concurrent programming</strong> is a huge deal and is a huge difference between systems programming and &#8220;traditional application programming,&#8221; which I&#8217;m starting to feel is like, the lame computer programming.<br /><br /><br /><br />Sources:<br />Lecture 2 notes<br /><a href="http://en.wikipedia.org/wiki/Moore's_law">Wikipedia: Moore&#8217;s Law</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/28/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/26/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About</h1>
  I&#8217;m Nadine. I like various things.  
</section>
<section>
  <h1>Other Places</h1>
  <ul>
    <li><a href="http://uxunicorn.com">Portfolio</a></li>
    <li><a href="http://neauro.tumblr.com">Tumblr</a></li>
    <li><a href="http://github.com/neauro">Github</a></li>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - nadine a. -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
