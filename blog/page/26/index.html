
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>liwanag</title>
  <meta name="author" content="nadine a.">

  
  <meta name="description" content="All of a Sudden His Code Started Throwing Compile Errors &#8211; Incorrect Syntax, Undefined Variables. Feb 28th, 2011 He dug through the source and &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.neauro.com/blog/page/26">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="liwanag" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<link href="http://fonts.googleapis.com/css?family=Metrophobic:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-46467190-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">liwanag</a></h1>
  
    <h2>things i learn, things i like</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:blog.neauro.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/28/all-of-sudden-his-code-started-throwing/">All of a Sudden His Code Started Throwing Compile Errors &#8211; Incorrect Syntax, Undefined Variables.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-28T00:00:00-08:00" pubdate data-updated="true">Feb 28<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
He dug through the source and saw her note, words inserted across the lines &#8211; a greeting here, with the global declarations &#8211; a nostalgic recollection of a summer day pinched between the paranthesees of a couple method calls.  He traced every error to a memory, an endearment, an apology.  At the end, just before the closing bracket, there was a farewell.<br /><br /><code>i'll miss you;</code></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/drabble/'>drabble</a>, <a class='category' href='/blog/categories/writing/'>writing</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/25/operating-system-notes-fat-file-system/">Operating System Notes: FAT File System</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-25T00:00:00-08:00" pubdate data-updated="true">Feb 25<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">Disk Geometry Definitions</span><br />So now we&#8217;re learning about disks (which I always end up spelling as &#8220;discs&#8221; somehow) as well as file systems.<br /><br />Some pertinent disk parts (which I always forget the definition of):<ul><li>the disk&#8217;s data is stored on concentric bands called <strong>tracks</strong>; tracks are more densely populated with data at the center of the disk than on the other edges (to ensure that a <strike>discked</strike> fixed amount of data can be read in a constant time, despite disk surface speed moving fast on the outer tracks)</li><li>tracks are divided into sections called <strong>sectors</strong>, which are the smallest unit of physical storage on the disk; the data size of a sector is always a power of two, and almost always 512 bytes</li><li>a <strong>cluster</strong> is what the Windows NT file systems use to allocate storage; a cluster is one or more contiguous sectors.</li></ul><br />As a file is written to the disk, the file system decides the appropriate number of clusters needed to store the file&#8217;s data.  For instance, if each cluster is 512 bytes and the file being written is 800 bytes, then two clusters are allocated for the file.  If the file size changes later, then more clusters are allocated to that file.<br /><br /><br /><br /><span class="sig">One type of file system: File Allocation Table (FAT)</span><br />So, a file system is a method of storing and organizing files and data on a computer.  Essentially, a file system organizes the files into a database so that the operating system can organize, manipulate, and retrieve them.<br /><br />Some basic differences (between FAT and NTFS file systems):<ul><li>The FAT file system can only use 16 bits for the cluster number, which means that volumes using the FAT format of file system can be larger than 65,535 sectors</li><li>Because of the overhead in the FAT file system, it&#8217;s not good for volumes larger than 511 MB (wait, isn&#8217;t this&#8230;all volumes nowadays?;;)</li><li>FAT is a better choice than NTFS for volumes that are smaller than ~400-500 MBs though, because of the disk overhead in NTFS.  I guess that&#8217;s the tradeoff</li><li>FAT file systems can be used with operating systems other than Windows NT, i.e. Windows 95, MS-DOS, etc.</li><li>FAT is simpler</li><li>FAT folder size is smaller for an equal number of files</li><li>FAT has no controls regarding whether a user can access a file or folder, which means the system doesn&#8217;t need to check permissions for an individual file or user, to see if the user has access to the file.  But Windows NT operating systems will have to check if a file is read-only anyway, whether it&#8217;s FAT or NTFS, which is why FAT may provide faster access to files in this respect</li></ul><br />FAT is a simple file system that was originally designed for small disks and simple folder structures. A FAT-formatted volume is allocated in clusters, the size of which is determined by the size of the volume, which must fit in 16 bits and must be a power of 2.<br /><br />FAT is named for the file allocation table, which lives at the beginning of a FAT-formatted volume.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-jw8lKfAxw60/TWX-0tUJQVI/AAAAAAAAAIs/9T9URTfof_c/s1600/FATvolume.jpg" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="62" width="320" src="http://3.bp.blogspot.com/-jw8lKfAxw60/TWX-0tUJQVI/AAAAAAAAAIs/9T9URTfof_c/s320/FATvolume.jpg" /></a></div><br />What do all of these areas do?  <strong>FAT1</strong> and <strong>FAT2</strong> contain the file allocation table, which contains information about a cluster on the volume, specifically whether that cluster is:<ul><li>unused</li><li>a cluster in use by a file</li><li>a bad cluster</li><li>the last cluster in a file</li></ul><br />The <strong>root folder</strong> contains an entry for each file and folder on the root.  The only difference between the root folder and other folders is that the root folder is in a specified location on the disk, and has a fixed size.  (On a hard disk, the size is 512 entries; on a floppy disk, it depends on the size of the floppy.)<br /><br />For every file and folder contained in a folder (as directories are really just a special type of file), there is a 32-byte entry, which contains the following information:<ul><li>name (eight-plus-three characters)</li><li>attribute byte (8 bits)</li><li>create time (24 bits)</li><li>create date (16 bits)</li><li>last access date (16 bits)</li><li>last modified time (16 bits)</li><li>last modified date (16 bits)</li><li>starting cluster number in the file allocation table (16 bits)</li><li>file size (32 bits)</li></ul><br />As for the FAT folder structure, there is no real organization &#8211; when a new file comes in, it is placed in the first available location on the volume.  The &#8221;<strong>starting cluster number</strong>&#8221; is the address of the first cluster used by the file.  Each cluster points to the next cluster used in the file, or else to a terminating cluster that signals the end of the file.<br /><br />Since all entries in a folder are the same size, the <strong>attribute byte</strong> for each entry in a folder describes what kind of entry it is: one bit indicating that it&#8217;s a subfolder, another bit marking the entry as a volume label, etc.  The OS controls the settings of these bits.  The user can control four other attribute bits, which indicate the entry is an archive file, system file, hidden file, and/or read-only file.<br /><br /><br /><br />More later.<br /><br /><br />Sources:<br />Microsoft TechNet: <a href="http://technet.microsoft.com/en-us/library/cc750198.aspx">Disk and File System Basics</a>, <a href="http://technet.microsoft.com/en-us/library/cc750355.aspx">Choosing a File System</a><br />Wikipedia: <a href="http://en.wikipedia.org/wiki/File_system">File system</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/25/aaaahhhh-rails/">AAAAHHHH RAILS</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-25T00:00:00-08:00" pubdate data-updated="true">Feb 25<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
I had a Rails work party with Joshu the other night (after which Rosanna served us basil-pesto pasta and lamb steak) and now I just want to do EVERYTHING IN RAILS.  It is SO COOL.  It&#8217;s so easy to work with databases and set everything up&#8230;.eeeeek &lt;3<br /><br /><span class="shh">Why am I taking operating systems when what I really want to do is just make sleek Rails apps/portfolio things .____.</span><br /><br />My main resources are <a href="http://railsforzombies.org/">Rails for Zombies</a> (a pretty site with cute, intelligible tutorials and nice lab sessions <span class="shh">which I mostly skipped, but, whatever</span>) and Kelly, who&#8217;s the best. :D<br /><br />Once I can figure out something to really make, and once I figure out how to get <a href="http://heroku.com">heroku</a> working, this world is going to be so much more fun.</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/fangirling/'>fangirling</a>, <a class='category' href='/blog/categories/rails/'>rails</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/17/operating-systems-notes-disk-caching/">Operating Systems Notes [Disk Caching, RAID Levels, Flash Memory)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-17T00:00:00-08:00" pubdate data-updated="true">Feb 17<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
This is a quick rehash of what we&#8217;ve learned in the previous week!<br /><br /><span class="sig">Disk Caching</span><br />So the OS can optimize operations done by scheduling things, either <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-5-cpu.html">CPU</a> or <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">memory</a>.  The operating system can also schedule disk operations, which are reads/writes from/to the disk (that far-off entity which stores the data you want, yet is time-consuming and expensive to reach).<br /><br /><strong>Disk scheduling</strong> is optimized especially through <strong>disk caching</strong>.  Disk caching can come in two flavors.  <strong>Write caching</strong> is when the user has the data that they want to write to disk, and the OS, rather than writing that data directly to the disk, instead writes it to a cache.  Then, sometime later, the OS writes everything in the cache to the disk.  There&#8217;s a sort of &#8220;five minute rule&#8221; to this, where (very roughly) every &#8220;five minutes or so,&#8221; the cache gets &#8220;flushed&#8221; to disk.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-wDujboA5CPU/TV4Ffh_w4XI/AAAAAAAAAHs/qyHyYUHJcPs/s1600/writecaching.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="81" src="http://3.bp.blogspot.com/-wDujboA5CPU/TV4Ffh_w4XI/AAAAAAAAAHs/qyHyYUHJcPs/s320/writecaching.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">our TA&#8217;s lecture notes are so cool</td></tr></tbody></table><br />There&#8217;s also <strong>read caching</strong>, which is when the operating system reads data from the disk into a cache, so as to be easily and quickly accessed by the user later.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-6A1WwUsxBH8/TV4FjpY-ETI/AAAAAAAAAH0/UahzFruaJtY/s1600/readcaching.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="83" src="http://1.bp.blogspot.com/-6A1WwUsxBH8/TV4FjpY-ETI/AAAAAAAAAH0/UahzFruaJtY/s320/readcaching.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">look at this. &nbsp;just look how understandable this is</td></tr></tbody></table><br /><br />One way to take advantage of disk caching is to use <strong>memory mapped I/O</strong>.  The data in a disk cache exists in kernel space, so what&#8217;s an easy way for a process in user-space to get a hold of it?  To have the process contain a mapping directly to that disk cache!<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-OU-tACxsM5Q/TV4GYm7X0jI/AAAAAAAAAH8/BQaW5asqgME/s1600/memorymappedio.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="126" src="http://2.bp.blogspot.com/-OU-tACxsM5Q/TV4GYm7X0jI/AAAAAAAAAH8/BQaW5asqgME/s320/memorymappedio.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">these colors are just so neat</td></tr></tbody></table><br />The segment of a process&#8217;s <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">virtual address</a> which has been mapped is called a <strong>memory-mapped file</strong>; in this case, it&#8217;s the blue part.<br /><br />As the process uses the file, it may need to write to it, which means eventually that the pages that the user-space process altered will need to be flushed to disk, or written out to disk.  The OS will know which pages to write thanks to the alteration of a dirty bit.  When the ditry bit is high, that means that the page has been altered and will need to be flushed.  <span class="shh">(Somehow this whole paragraph feels a little gross&#8230;)</span><br /><br /><br /><span class="sig">RAID Levels</span><br />are another thing that we&#8217;ve been talking about in lecture.  The thing about disks in general is that though they are a pretty useful/necessary storage device for computers, they&#8217;re super messy &#8211; they run into errors all the time, like bad blocks, or missed seeks.  Part of the job of the operating system is to hide all this messy-ness from higher-level software (i.e. software that other, more sane programmers will write to be run on the computer).  The OS will provide different levels of access to different clients &#8211; for instance, allowing them to access physical disk blocks (a specific head, or cylinder of the disk) or just logical disk blocks (i.e. a program says &#8220;I want disk 6&#8221; and the OS retrieves the real location of &#8220;disk 6&#8221; itself).<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-pZ8QGur6iSg/TV4MPA-H3hI/AAAAAAAAAIE/Sv47rFhynK0/s1600/harddrive.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="223" src="http://4.bp.blogspot.com/-pZ8QGur6iSg/TV4MPA-H3hI/AAAAAAAAAIE/Sv47rFhynK0/s320/harddrive.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">this is what a disk looks like, by the way</td></tr></tbody></table><br />It takes time for an OS to find something on a disk.  The performance is based on three main things:<br /><ol><li><strong>Seeking</strong>: how long it takes to move the disk arm to the correct cylinder on the disk</li><li><strong>Rotation</strong>: how long it takes to wait for the sector you want to rotate under the head of the reader.  This depends on the rotation rate of the disk, which is not increasing that quickly, mainly because the way disks are made now, if they spin any faster they&#8217;ll fall apart</li><li><strong>Transfer</strong>: how long it takes to transfer data from the surface of the disk into the disk controller, and from there back to the process that wants the data</li></ol><br />The OS mainly tries to reduce seek times and rotation.<br /><br />So, since disk transfer rates in general are improving, and since CPU performance isn&#8217;t, what you can do to improve performance is have multiple disks containing/transferring data.  In particular, you can &#8220;stripe&#8221; files across multiple disks by placing parts of each file on a different disk, making it so that you can read parts of a file simultaneously (i.e. use <strong>parallel I/O</strong> to read a single file).<br /><br />The problem with striping is that it&#8217;s not very reliable.  To improve its reliability, you can add redundant data to the disks, along with striping, and thus &#8211; <strong>RAID: Redundant Array of Inexpensive Disks</strong>.  Since disks are physically small and cheap, you can just stick a lot of them into one box to increase storage, performance, and availability.  Depending on how you stripe data, you can affect resulting performance and reliability in different ways.<br /><br />What are some things to consider in different methods of striping?  Firstly, <strong>granularity</strong>.  If you stripe each file across multiple disks (&#8220;fine-grained&#8221; granularity), you will get high throughput for reading the file, but limit overall transfer to one file at a time.  If you stripe each file over only a few disks (&#8220;coarse-grained&#8221; granularity), you limit throughput for 1 file, but can have concurrent access to multiple files.<br /><br />Another thing to think about is the <strong>redundancy</strong> itself.  If you uniformly distribute redundancy, then you&#8217;ll avoid load-balancing problems.  You can also concentrate redundancy information on a subset of your total disks, and make it so that some of your total disks are &#8220;data disks&#8221; and the others are &#8220;redundancy disks.&#8221;<br /><br />So what are the different types of RAID?<br /><br /><strong>RAID Level 0</strong> is when you have a non-redundant disk array &#8211; files are just striped across disks, with no redundant info saved at all.  There&#8217;s high read throughput (since you can do the parallel I/O thing), and also high write throughput (since you don&#8217;t need to write redundant info).  However, if one of your disks fails, then you can lose the file and sometimes the entire volume, which is horrible. D: D:<br /><br /><strong>RAID Level 1</strong> is also known as &#8220;mirrored disks.&#8221; Files are striped across half the disks, and when you write data, it gets written to both a &#8220;data disk&#8221; and the &#8220;mirror disks,&#8221; which are copies of the data disk.  This way, if the data disks fail, you can just use the surviving disks.  A downside to this technique is that you need to have 2N the amount of space to hold N amount of data, understandably.<br /><br /><strong>RAID Level 2, 3, 4</strong> all pretty much have the same idea, I guess &#8211; they all use error correcting code (ECC) or <strong>parity disks</strong> to provide fault tolerance.  Each byte on a parity disks is a parity function of the corresponding bytes on all the other disks.  This way, a read accesses all data disks.  A write accesses all data disks, as well as the parity disk.  If the disk fails, read what you have of the file and then use the parity disk to compute the missing data.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-hxvTkkUW3Bs/TV4N-F5JUiI/AAAAAAAAAIM/CHZ7y8sofE0/s1600/parity%2Bdrives.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="105" src="http://2.bp.blogspot.com/-hxvTkkUW3Bs/TV4N-F5JUiI/AAAAAAAAAIM/CHZ7y8sofE0/s320/parity%2Bdrives.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">yeah! &nbsp;go parity drive, go!</td></tr></tbody></table><br />But, <strong>what is parity, again?</strong> I guess, given a byte, you want to add a bit set so that the total number of 1&#8217;s in the byte is even; that way, any single missing bit can be reconstructed.  Parity bites are used as the simplest form of error detecting.<br /><br /><strong>RAID Level 5</strong> uses <strong>block interleaved distributed parity</strong>, which is just like the parity scheme of earlier RAIDs, but instead of having one parity disk, the parity info is distributed across all disks.  For each block, one disk holds the parity, and the other disks hold the data.  This type of RAID has significantly better performance, since the parity disk is not a hot spot.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-MwfHA3qWfcQ/TV4O_26wZlI/AAAAAAAAAIU/FyZ1f6cnCsA/s1600/raid5.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="150" src="http://4.bp.blogspot.com/-MwfHA3qWfcQ/TV4O_26wZlI/AAAAAAAAAIU/FyZ1f6cnCsA/s320/raid5.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">RAID Level 5 disk layout</td></tr></tbody></table><br />So when you use RAID, you can also use a <strong>RAID controller</strong>, which is embedded in the hardware.  A RAID controller can make it seem to the OS like the many disks you&#8217;re using is actually just one disk.<br /><br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-gvTCVSUmMAU/TV4PdUh6pbI/AAAAAAAAAIc/qiESnTQW4-M/s1600/raidcontroller.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="135" src="http://4.bp.blogspot.com/-gvTCVSUmMAU/TV4PdUh6pbI/AAAAAAAAAIc/qiESnTQW4-M/s320/raidcontroller.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">&#8220;What&#8217;s that? &nbsp;I only have one disk? &nbsp;Oh, cool&#8221;</td></tr></tbody></table><br />The advantages of putting <em>policy</em> in the RAID controller is that it makes the OS&#8217;s job easier.  The disadvantage is that every time you put a layer of abstraction into something, you ruin the chance of optimizing it.  So, putting this layer of abstraction makes the OS a little simpler to program, but now you can&#8217;t optimize the OS (like, using disk scheduling effectively) the way you could if the OS <em>did</em> have control of and was aware of all of its assets.<br /><br /><br /><span class="sig">Solid State Disks (Flash)</span><br />We also talked about flash drives, which was pretty interesting.  Like disks, the data on a flash drive is stored in blocks.  Since there aren&#8217;t any spinning platters, random access is fast, and you don&#8217;t need disk scheduling algorithms.  It&#8217;s very fast to read from a flash drive thanks to the random access, but slower to write to a flash drive, because the flash media must be erased before it can be written to.  So, when you&#8217;re writing to a solid state drive like a flash drive, you&#8217;re actually a) reading some block, b) erasing that block, c) writing back the modified block.  But, there are ways of &#8220;hiding the warts of an SSD&#8221; (as these section notes put it), mostly by virtualizing pages and blocks on the drive (so you&#8217;re working with logical pages, not physical pages), and doing &#8220;wear-leveling,&#8221; which is when you try to spread our the erasure of blocks evenly over the drive.<br /><br />Meanwhile, what is a solid-state drive?  Evidently it&#8217;s just a data storage device toat uses solid-state memory to store persistent data.  &#8220;Solid-state&#8221; refers to a type of electronics which are build entirely from solid materials, within which electrons or other charge carriers are confined within the solid material.  Solid-state memory I think is like RAM, which gets erased once you shut down your computer, but as of 2010, most solid-state drives use NAND-based flash memory, which can hold memory even if there&#8217;s no power running through it.  &#8220;NAND flash&#8221; just refers to the way that the transistors are hooked up in the flash drive: in a way that resembles a NAND gate.<br /><br />Sources:<br />section 7 notes<br /><a href="http://en.wikipedia.org/wiki/Memory-mapped_file">Wikipedia: Memory-mapped file</a>, <a href="http://en.wikipedia.org/wiki/Parity_disk">Parity Drive</a>, <a href="http://en.wikipedia.org/wiki/Parity_bit">Parity bit</a>, <a href="http://en.wikipedia.org/wiki/Solid_state_drive">Solid-state drive</a>, <a href="http://en.wikipedia.org/wiki/Solid-state_(electronics)">Solid state (electronics)</a>, <a href="http://en.wikipedia.org/wiki/Flash_memory#NAND_flash">NAND flash</a><br />lecture 12 notes (&#8220;Disk&#8221;)<br />lecture 13 notes (&#8220;Raid and Volumes&#8221;)</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/16/game-bonding-time/">Game: Bonding Time</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-16T00:00:00-08:00" pubdate data-updated="true">Feb 16<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-u0vR2MtUWDw/TVyji_MufeI/AAAAAAAAAHU/eDXX8Sa_udg/s1600/bondingtime_titlescreen.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="239" src="http://4.bp.blogspot.com/-u0vR2MtUWDw/TVyji_MufeI/AAAAAAAAAHU/eDXX8Sa_udg/s320/bondingtime_titlescreen.png" width="320" /></a></div><br />So yesterday we finally finished the atom game that me, Jimmy, Leilani, and Chris have been trying to do for the <a href="http://www.facebook.com/haproject">Zynga &amp; Hidden Agenda</a> competition.  The point of the competition is to make a game which will &#8220;teach high school students&#8221; someting.  We all signed up around September and November with the initial idea of making something that would be like Oregon Trail but for ethnic studies, but eventually decided against it because ethnic studies (done right) is a subject that&#8217;s not taught properly in high school for a reason (i.e. general controversy), I think :/<br /><br /><span class="shh">So, that game will come later.</span><br /><br />Over winter break (during which I was rabidly playing <a href="http://nuubu.blogspot.com/2010/12/9-hours-9-persons-9-doors.html">999</a>) there was one scene (spoilers?) with a passcode that you figured out based on the number of atoms in a molecule, so I got the idea of making a game based on how atoms bond with respect to valence electrons, and how (most) atoms strive to have eight valence electrons and will form bonds with other atoms to achieve this.<br /><br />Since 90% of my AP Chem course in high school was all about memorization, I thought that some advantages of a game like this would:<br /><ul><li>provide a slightly more fun way to memorize things like all the polyatomic ions that the College Board decided were important to memorize</li><li>also help people visualize more how atoms get bonded together, hopefully leading to understanding of why something like organic chemistry is its own course (apparently because carbon is super good at bonding with itself; who knew)</li></ul><br />I met with Alex over winter break and to get a refresher on chemistry (which I haven&#8217;t thought about since those ancient high school times) and (in between greeting people returning to Homedale Mall for the holidays <span class="shh">(Maggie and Colin are getting married!!)</span>) we went over a couple concepts.  He pointed out that rather than rote memorization, it would be more helpful to remember certain patterns of bonding (somthing related to alkanes and alkenes, etc.) and also had good ideas of a sort of RPG-style game where you could level up and create different types of bonds by applying heat and other chemicals and stuff. In the end I think that will be saved for another possible game, since I couldn&#8217;t understand it myself well enough to try and teach it to other people (despite the fact that I realize teaching something is the best way to learn it).  In any case, I wanted to keep it pretty simple.<br /><br />So then the gameflow started to look like:<br /><ol><li>Game gives players a molecule to assemble (i.e. &#8220;OH,&#8221; H20&#8221;), as well as a random assortment of atom sprites</li><li>Player tries assembling putting the required atoms together (i.e. pushing together an &#8220;O&#8221; and an &#8220;H&#8221; atom)</li><li>Player is rewarded with points and a mildly amusing (yet honest) description of what role that molecule plays in Everyday Life</li><li>Rinse, lather, repeat</li></ol><br />After that, we all met and broke down into separate teams.  We decided to use <a href="http://flixel.org/">Flixel</a> (which Kathleen showed me and I was super excited to use! :D) and then tried to work out the implementation.  Other than managing the state of the game (i.e. points, timer, propagating atoms to the screen) the main difficulties turned out to be <strong>bonding</strong> atoms, and <strong>validating</strong> bonds that the player had made.  I wanted the game not just to see that the molecules players assembled where all together, but that they were bonded in the right places &#8211; so if a player were trying to bond H20, a bond that went like<br /><br /><br /><center>H-H-O</center><br /><br />would be invalid, whereas something like<br /><br /><br /><center>H-O-H</center><br /><br />would be, since the real-life situation is that a pair of H atoms bond to an O.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-Zyh-voWylFI/TVyyl3vz5-I/AAAAAAAAAHk/YH9wL6cdILk/s1600/Covalent_H2O.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="310" src="http://1.bp.blogspot.com/-Zyh-voWylFI/TVyyl3vz5-I/AAAAAAAAAHk/YH9wL6cdILk/s320/Covalent_H2O.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">like so! (<a href="http://commons.wikimedia.org/wiki/File:Covalent_H2O.png">source</a>)</td></tr></tbody></table><br />In the end, the bonding function came to deal purely with atom behavior, i.e. atoms being moved about by the player and sticking together and then moving as one once they were &#8220;bonded.&#8221; Atoms contained data about who their neighboring atoms were.  Validation took a single molecule, then compared the connections and neighbors against a &#8220;validation code.&#8221;<br /><br />So, if we had the case of H-O-H, we could make a &#8220;validation code&#8221; which would contain data about the correct neighbors of each atom &#8211; in this case, <code>h_o1-o_h2-h_o1</code>, which meant &#8220;a hydrogen with 1 oxygen neighbor, an oxygen with 2 hydrogen neighbors, a hydrogen with 1 oxygen neighbor.&#8221;<br /><br />It worked :D And it meant that atoms could be bonded in any order, yay!<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-ZWKDaDp6U4k/TVysvYL3ycI/AAAAAAAAAHc/Mgg9I_Hfu7Y/s1600/bondingtime_firstbond.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="238" src="http://3.bp.blogspot.com/-ZWKDaDp6U4k/TVysvYL3ycI/AAAAAAAAAHc/Mgg9I_Hfu7Y/s320/bondingtime_firstbond.png" width="320" /></a></div><br />The game is <a href="http://neauro.com/flash/atomgame.swf">here</a>.  We&#8217;ve turned it in, but I can&#8217;t help thinking of all the things that I would have wanted to change if we had more time&#8230; (.___.  I guess I can add it in the future.  Specifically:<br /><ul><li>put in some visual cue about which molecule is &#8220;selected&#8221; to bond (right now, the molecule which will get checked is just the last one clicked)</li><li>put in more visual cues about how electrons get shared between atoms (i.e. if two fluorine atoms get placed together, it should show that they both share one electron to bring each one&#8217;s total number of valence electrons to 8)</li><li>put in more visual cues about the nature of bonds in a molecule (i.e. if it&#8217;s a single or double bond)</li><li>put an undo button, for goodness sake; if someone makes a mistake right now, you just have to refresh the whole set of atoms on screen D:</li><li>better icons for bond/reset/skip functions (since according to <em>The Design of Everyday Things</em>, text labels on anything indicate poor design)</li><li>add more, and more interesting, atoms</li><li>add a bonus round of some sorts, where maybe the objective would be to just try and get as many atoms as you can bonded together&#8230;I don&#8217;t know -shrug-</li></ul><br /><br /><br />&#8230;my very first game!  I&#8217;m still pretty proud. :D</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>nadine a.</div>
<div class='content'>
Haha, thanks. :D But c&#39;mon, you have done some pretty amazing stuff as well!  You do a ton more little experiments then I do, and have been learning about things for much longer!</div>
</div>
<div class='comment'>
<div class='author'>axcho</div>
<div class='content'>
Wow, you actually did this? That&#39;s awesome. I wanted to do something like this back when I was taking chemistry classes. I feel like a loser who comes up with ideas and then never actually does them. You&#39;ve done all this cool stuff and found people to do them with.<br /><br />I congratulate you!</div>
</div>
</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/game-design/'>game design</a>, <a class='category' href='/blog/categories/games/'>games</a>, <a class='category' href='/blog/categories/programming/'>programming</a>, <a class='category' href='/blog/categories/project/'>project</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/15/chocobos-nooooo/">CHOCOBOS. NOOOOO</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-15T00:00:00-08:00" pubdate data-updated="true">Feb 15<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-HRBgV5lMWMQ/TVq_JofqSRI/AAAAAAAAAHM/09kAvAvaRVA/s1600/chochoco.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="574" src="http://1.bp.blogspot.com/-HRBgV5lMWMQ/TVq_JofqSRI/AAAAAAAAAHM/09kAvAvaRVA/s640/chochoco.jpg" width="640" /></a></div><br />So I&#8217;ve been playing social games as research for my Informatics class, and in general been pretty skeptical of the whole thing (outside of FarmVille, which I find myself enjoying slightly more than the others, maybe just because it&#8217;s a farm sim and it feeds my &#8220;pastoral ideal,&#8221; which I recently learned that I possess thanks to <em>The Omnivore&#8217;s Dilemma</em>) &#8211; and then.<br /><br /><em>A chocobo game?</em><br /><br /><span class="shh"><em>I love birds/chickens/chocobos/the pastoral ideal.  It&#8217;s even red.  Red is my favorite color.</em></span><br /><br />It&#8217;s over.  It&#8217;s over for me.<br /><br />.___.</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/games/'>games</a>, <a class='category' href='/blog/categories/video-games/'>video games</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/11/operating-systems-notes-virtual-memory/">Operating Systems Notes [Virtual Memory, Page Tables, TLBs]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-11T00:00:00-08:00" pubdate data-updated="true">Feb 11<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So in case <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">it wasn&#8217;t clear already</a>, <a href="http://en.wikipedia.org/wiki/Virtual_memory">virtual memory</a> is a memory management technique which accomplishes these things:<ul><li>hides fragmentation of physical memory from programs</li><li>uses hardware memory more efficiently than systems without virtual memory</li><li>lets a program be designed as though there&#8217;s only one hardware memory (rather than one memory split up between different processes, I think?)</li></ul><br />An important aspect of implementing virtual memory is page tables.  A page table translates a program&#8217;s virtual address (used to refer to a function or variable or whatnot) into a physical address (which is the actual location of that function&#8217;s code data, or the variable&#8217;s value data).  Page tables make it so that programs can only be partially loaded into memory.  <strong>So, what happens when a program tries to access a part of its code which isn&#8217;t loaded into memory?<br /><br />A PAGE FAULT.</strong><br /><br />When a page fault happens,<ol><li>the OS is given an <a href="http://nuubu.blogspot.com/2011/01/operating-system-notes-chapter-1.html">interrupt</a></li><li>the OS saves the state of the running process, then searches (in the appropriate vector) for the page fault handler routine)</li><li>the page fault handler routine will find or create (through eviction) a page frame into which to load the page that the program needs</li><li>then it will find that page on the disk and place it into the now-free page frame</li><li>then it will fix up the page table entry &#8211; marking it &#8220;valid,&#8221; setting the &#8220;referenced&#8221; and &#8220;modified&#8221; bits to false, setting the pointers properly</li><li>finally, the process is placed back into the ready queue</li></ol><br />Anyway, it&#8217;s getting late and I want to go to bed so for now I&#8217;ll just skip to<br /><br /><br /><span class="sig">Translation Lookaside Buffers (TLBs)</span><br />to whom we must extend our gratitude for not making page tables awful.  Think about it: if you have a virtual address and you need to look into the page table and then into the physical address in order to actually obtain some value, that&#8217;s a <em>lot</em> of overhead.<br /><br />To make this more efficient, you want to make fetching from a virtual address just about as efficient as fetching from a physical address.  Which you can do with an extra piece of hardware, a cache inside the CPU.<br /><br />Thus, virtual-to-physical translations are cached in the hardware itself, the TLB.  The TLB translates virtual page numbers into page frame numbers (<em>not physical addresses</em>), and can do it in a single machine cycle.  The TLB in turn is managed by the memory management unit (MMU), which is what calculates the physical address from the page table entry and an offset.<br /><br />TLBs exploit the fact that processes have good temporal locality and spatial locality.  This is a fancy way of saying that processes tend to<ul><li>use data/code they have recently used</li><li>use data/code that is close to data/code they have recently used</li></ul>Which is why <em>caching</em>, or saving that data in an easily accessible place (as you may cache your potato chips, water bottles, and chocolate beneath the bedside  table) is a good idea.<br /><br />So, the TLB does the translation between virtual addresses and page frame numbers, and when it misses &#8211; when it can&#8217;t find a page frame number &#8211; the translation is saved into the TLB by the OS.<br /><br />In order for TLBs to work, the OS must make sure the TLB and page tables are consistent and up-to-date, and <strong>when a context switch happens, the TLB must be completely flushed</strong>, which means that context switching is still an expensive operation &#8211; all those cached translations, that optimization, disappears.  (The TLB needs to be flushed rather than saved and loaded with the rest of the process state because there&#8217;s no guarantee that other processes wouldn&#8217;t mess around with the data the TLB was keeping track of, and to keep the TLB up-to-date when it isn&#8217;t being presently used by a process is expensive.)<br /><br /><br /><br />Sources:<br /><a href="http://en.wikipedia.org/wiki/Virtual_memory">Wikipedia: Virtual memory</a><br />lecture 11a notes</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/11/operating-systems-notes-memory/">Operating Systems Notes [Memory Management]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-11T00:00:00-08:00" pubdate data-updated="true">Feb 11<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="sig">What&#8217;s so cool about memory management anyway bro</span><br />So unlike way back when in the time of punchcards &amp; etc., we use computers which are capable of <strong>multiprogramming</strong>, a feature of which is the ability to have multiple processes and jobs in memory all at once.<br /><br />We&#8217;ve already looked at ways that an operating system&#8217;s <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-5-cpu.html">processing power</a> can be utilized effectively when you have many different processes executing simultaneously, but how can memory &#8211; also a scarce resource in a computer &#8211; be distributed across processes?  The goal of memory management is to <strong>maximize memory utilization and system throughput</strong>.<br /><br />You also have to make sure that you can manage memory so as to:<br /><ol><li><strong>Protect</strong>: that is, make sure processes execute in isolation, so they don&#8217;t interfere with each other</li><li><strong>Translate fast</strong>: that is, make sure that memory lookups are speedy despite the fact that protection kind of slows stuff down</li><li><strong>Context switch fast</strong>: that is, make sure memory hardware is updated when old processes are removed from the CPU and new processes are given to it</li></ol><br />On a hardware level, when you&#8217;re dealing with memory, you&#8217;re really messing around with <strong>base registers</strong> and <strong>limit registers</strong>.   Base registers contain the address of a start of a program,  and limit registers contain the length of the program.  Both of these things define the scope of a program&#8217;s memory.<br /><br />Programs get their code and data loaded into memory so that they can be run in processes.  It&#8217;s important to keep the memory that processes use separate, so that they don&#8217;t interfere with each other, overwriting the other program&#8217;s code and making it crash and such.  The memory that a program has is allocated is called its <strong>address space</strong>.  In the olden days, if a program couldn&#8217;t fit into memory, then you&#8217;d have to manually overwrite parts of the code that you weren&#8217;t using presently.<br /><br /><br /><span class="sig">Virtual Memory</span><br />Virtual memory is an abstraction provided by the operating system for memory management.  Thanks to virtual memory, we can do cool things like:<br /><ul><li>allow programs to execute even if their entire address space isn&#8217;t in physical memory</li><li>let programs execute with less RAM than they really &#8220;need&#8221;</li><li>isolate processes from each other so that they can&#8217;t name addresses that other processes can use</li></ul>This is mainly because programs don&#8217;t really use all of the code that they&#8217;re written with &#8211; for instance, a program with if-statements will either execute one branch of the if-statement or the other, and there&#8217;s no real need to allocate space for code that isn&#8217;t run.<br /><br />On a hardware level, virtual memory relies on translation-lookaside buffers (TLB&#8217;s), page tables, page fault handling&#8230;you&#8217;ll also need to deal with swapping and segmentation.  <strong>Swapping</strong> is the memory-equivalent of context switching for processing power.  When you do a context switch between processes, you remove the old process from using CPU and allocate that CPU to the new process; in swapping, you remove memory from the previous process and give it to the new one.<br /><br /><br /><span class="sig">Virtual Addresses</span><br />So, this whole time when we&#8217;ve been talking about how <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-2-3.html">a process consists of an address space</a> (along with at least one thread and OS resources), what we&#8217;ve really meant is that processes have a set of <strong>virtual addresses</strong>.  Once more: a process&#8217;s address space is its set of virtual addresses.<br /><br />And what are virtual addresses?  They are the layer of abstraction between a process and physical memory.  When the CPU executes instructions from a loaded program, it uses the virtual addresses for pointers, arguments to load and store instructions, and so on.  Virtual addresses must be translated by hardware into physical addresses, the actual location of the data stored on disk.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-KotutHv0Kkk/TVTbDb2stkI/AAAAAAAAAGE/c_t2mc_tACA/s1600/viraddr1.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="226" src="http://4.bp.blogspot.com/-KotutHv0Kkk/TVTbDb2stkI/AAAAAAAAAGE/c_t2mc_tACA/s320/viraddr1.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">so, here we&#8217;ve got: process p&#8217;s pointer, which points to a virtual address in p&#8217;s address space. &nbsp;that in turn points to a physical address in physical memory.  the physical address is what points to the actual data.</td></tr></tbody></table><br /><br /><span class="sig">How do you translate virtual addresses into physical addresses?</span><br />Virtual addresses (in the process address space) and physical addresses (on disk) don&#8217;t correspond exactly to each other &#8211; that is, a virtual address in space 0 doesn&#8217;t necessarily point to a physical address in space 0.  So, how does a virtual address translate to a physical address?<br /><br />To translate in the olden days, the physical memory would be partitioned, in one of two ways:<br /><ol><li><strong>Fixed partitions.</strong>  The physical memory would be broken up into fixed-size partitions, so that the physical address could be obtained by adding the virtual address and the base register.  When a context switch happened, a new base register would be loaded.  This was a simple way of doing things but has <strong>fragmentation problems</strong> &#8211; both <strong>internal fragmentation</strong> (which happens when the physical memory partition is larger than what the program needs) and <strong>external fragmentation</strong> (which happens when you may have two small partitions remaining, and one large job which won&#8217;t fit into each separately).<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-Ty-M47nOJzo/TVTdQWMAdkI/AAAAAAAAAGM/ftBjaeeoabo/s1600/viraddr2.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="203" src="http://4.bp.blogspot.com/-Ty-M47nOJzo/TVTdQWMAdkI/AAAAAAAAAGM/ftBjaeeoabo/s320/viraddr2.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">with fixed partitions,<br />physical address = virtual address + base register<br />the limit register check is to make sure you don&#8217;t overstep physical memory</td></tr></tbody></table><br /></li><li><strong>Variable partitions.</strong> In this case, the physical memory would be broken up into variable-size partitions, the size dependant on the program.  Again, the physical address is equal to the virtual address plus the base register.  Variable partitioning <strong>fixes internal fragmentation</strong>, since you won&#8217;t allocate more than a program needs and therefore waste space that other programs could use &#8211; <strong>but you still have external fragmentation</strong>, because as you load and unload jobs, holes are left scattered behind.  (This is slightly different than external fragmentation in fixed partition systems.)<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-4zihtB6CQNQ/TVTeWbpF6jI/AAAAAAAAAGU/0-y3xwKJIkI/s1600/viraddr3.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="245" src="http://1.bp.blogspot.com/-4zihtB6CQNQ/TVTeWbpF6jI/AAAAAAAAAGU/0-y3xwKJIkI/s320/viraddr3.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">with variable partitions,<br />physical address = virtual address + base register<br />the limit register makes sure you don&#8217;t overstep memory<br />the black parts denote unused holes in the memory 3:</td></tr></tbody></table></li></ol><br /><br />One way to deal with external fragmentation is to be like,<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-iVkxoUAgHa0/TVTfpWKPs_I/AAAAAAAAAGc/5ngILCCIYpQ/s1600/viraddr4.jpg" imageanchor="1"><img border="0" height="234" src="http://3.bp.blogspot.com/-iVkxoUAgHa0/TVTfpWKPs_I/AAAAAAAAAGc/5ngILCCIYpQ/s320/viraddr4.jpg" width="320" /></a></div><br />and basically push all the allocated physical memory together.  Which is bad because you have to do this manually and like, all the time.<br /><br />So, a better way to do things in general is to be like, PAGES, BRO.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-29MhcnKDPZQ/TVTf8yOllPI/AAAAAAAAAGk/xqYlIwU95HQ/s1600/viraddr5.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="250" src="http://3.bp.blogspot.com/-29MhcnKDPZQ/TVTf8yOllPI/AAAAAAAAAGk/xqYlIwU95HQ/s320/viraddr5.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">PAGES. &nbsp;YE</td></tr></tbody></table><br /><br /><span class="sig">Pages and Page Tables</span><br />So with pages, processes view their address space as some memory ranging from indexes 0 to N, but in reality the mapping of those address spaces to physical addresses points every which way all over the disk.  The program doesn&#8217;t know this at all, and isolation is still provided to all program&#8217;s because a program still can&#8217;t reference memory outside of its virtual address space.<br /><br />So.  A virtual address is comprised of a virtual page number (VPN), as well as some offset.  A physical address is comprised of a page frame number (PFN), as well as some offset.  Now, to translate from a virtual address to a physical address, you need to divide the address space into equal-sized &#8220;pages,&#8221; and then use one more thing: the <strong>page table</strong>.  The page table contains the mapping between a virtual address&#8217;s VPN and a physical address&#8217;s PFN, and this is how a program with a virtual address can access physical memory, memory on disk.  Once more, for good measure: a page table maps a <em>virtual address page</em> to a <em>physical page frame</em>.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/_SdPKamJbrgg/TVThyWocAlI/AAAAAAAAAGs/cQVcDkDCC0U/s1600/viraddr6.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="215" src="http://4.bp.blogspot.com/_SdPKamJbrgg/TVThyWocAlI/AAAAAAAAAGs/cQVcDkDCC0U/s320/viraddr6.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">it&#8217;s easy, right?</td></tr></tbody></table><br /><br />Page tables contain <strong>page table entries (PTEs)</strong>, which look something like this:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TVTiaKBOuiI/AAAAAAAAAG0/EutComkh8Jg/s1600/viraddr7.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="91" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TVTiaKBOuiI/AAAAAAAAAG0/EutComkh8Jg/s320/viraddr7.jpg" width="320" /></a></div><ul><li>the <strong>valid bit</strong> says whether or not this PTE can be used &#8211; that is, whether or not the virtual address is valid, meaning it actually maps to some physical address, which points to a location in physical memory.</li><li>the <strong>referenced bit</strong> says whether the page has been accessed &#8211; that is, whether it&#8217;s been read from or written to at all</li><li>the <strong>modified bit</strong> says whether or not the page is dirty, meaning a write has occurred to that page</li><li>the <strong>protection bits</strong> control which operations (read, write, execute, etc.) are allowed to be used on this page</li><li>and finally, the PFN determines the &#8220;physical page,&#8221; the location in physical memory that the given virtual address points to.  Like how a base register contains the starting address of a process&#8217;s virtual address space, a physical page&#8217;s start address is determined by the PFN.</li></ul><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-IjOgv0A9WCU/TVTurOC7yJI/AAAAAAAAAHE/1vfxhYR5OlA/s1600/viraddr9.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="232" src="http://2.bp.blogspot.com/-IjOgv0A9WCU/TVTurOC7yJI/AAAAAAAAAHE/1vfxhYR5OlA/s320/viraddr9.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">here&#8217;s the picture from earlier without the page table photoshopped out of it</td></tr></tbody></table><br /><br /><strong>The great thing about paging</strong> is that makes it easy to allocate physical memory to a program &#8211; physical memory is now ordered in a list of frames, and when you want to allocate it, just remove it from the list of &#8220;free&#8221; frames.  This solves external fragmentation and all the troublesome-ness of managing the holes left behind from loading and unloading programs.<br /><br />And, it lends itself naturally to <strong>virtual memory</strong>, because a program doesn&#8217;t need to be completely resident in the memory anymore &#8211; only partially, only the parts that you care about right now (or soon).  If it so happens that you need code that is not presently in memory (which you&#8217;ll know, because when you use a virtual address to access something not in memory, the valid bit in the PTE will cry out), you take a <strong>page fault</strong>, and the code or data that you need will be brought into memory.<br /><br />Remaining problems: internal fragmentation, since a process still may not use memory in exact multiples of pages.  Also, there&#8217;s a great overhead in referencing anything, since instead of accessing that thing directly, you&#8217;re making two look-ups, first through the page table, and then into physical memory itself.  <span class="shh">(This can be solved with TLBs &#8211; more on that later.)</span><br /><br />The other problem: page tables can be huge.  Consider that each process has its own address space, which means you need one page table entry per page in the address space.  Operating systems typically have separate page tables per process, and things can get huge fast.  The solution to this is to&#8230;page the page tables lol.<br /><br /><br /><span class="sig">And yet another way to translate virtual addresses into physical addresses: segmentation</span><br />To do segmentation, partition not the physical memory, but the address spaces, into logical units: one partition for stack, one for code, one for the heap, one for subroutines&#8230;<br /><br />A virtual address that is a part of this address space will then consist of a <strong>segment number</strong> and an <strong>offset</strong>.<br /><br /><strong>The good thing about this: it&#8217;s more logical</strong>, since without segmentation, what the linker does during compilation is take a bunch of modules that call each other and linearizes them.  These modules are all independent and are treated that way when the address space is segmented.  Segmentation is also a natural extension of variable-sized partitions; where there&#8217;s one variable partition per process, there&#8217;s many segments per process.  Segmentation also facilitates sharing and reuse of code.<br /><br /><strong>Disadvantages: just like a variable partition system, segmentation can have all the horrific external fragmentation, even if linking is simpler.</strong><br /><br />On a hardware level, you would need a segment table with multiple base/limit register pairs, one per segment in the address space.  The physical address would be yielded by adding the virtual address offset to the base address of the segment.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TVTsVUM3gXI/AAAAAAAAAG8/rfJKLzVUE18/s1600/viraddr8.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="238" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TVTsVUM3gXI/AAAAAAAAAG8/rfJKLzVUE18/s320/viraddr8.jpg" width="320" /></a></div><br />Anyway, to fix the problem that segmentation has with external fragmentation, you can mix segmentation and paging.  Use segments to manage logical units, and then use paging to partition segments into fixed-size chunks.  Each segment will have its own page table (rather than there being one page table per address space), and memory allocation once again becomes easy and cool, without external fragmentation problems.<br /><br /><br /><br />Sources:<br />lecture 10 notes<br /><a href="http://www.science-dictionary.com/definition/base-register.html">Science-Dictionary: base register</a><br /><a href="http://answers.yahoo.com/question/index?qid=20090520065552AAOWEvZ">Yahoo Answers: Base and limit register?</a><br />section 5 notes</div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/05/okay-dude-so-planting-nachos-is/">Okay Dude, So, Planting Nachos Is Actually Kind of Cute</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-05T00:00:00-08:00" pubdate data-updated="true">Feb 5<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4ySbyJ4dI/AAAAAAAAAFk/Ipk2855l4uk/s1600/nachos1.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="534" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4ySbyJ4dI/AAAAAAAAAFk/Ipk2855l4uk/s640/nachos1.jpg" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TVBwgqjNpbI/AAAAAAAAAF0/qtPvgGw2FOI/s1600/nachos01.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="532" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TVBwgqjNpbI/AAAAAAAAAF0/qtPvgGw2FOI/s640/nachos01.jpg" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TVByO8ZIlfI/AAAAAAAAAF8/NTGFfh633Ko/s1600/nachos02.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="532" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TVByO8ZIlfI/AAAAAAAAAF8/NTGFfh633Ko/s640/nachos02.jpg" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4yXQ69pVI/AAAAAAAAAFs/Imea2ZBUA_I/s1600/nachos3.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="532" src="http://3.bp.blogspot.com/_SdPKamJbrgg/TU4yXQ69pVI/AAAAAAAAAFs/Imea2ZBUA_I/s640/nachos3.jpg" width="640" /></a></div><br />Other things I approve of:<br /><ul><li>being able to sell bushels of stuff</li><li>apparently being able to craft stuff when I reach level 25 (after I get tons of people to help me build the wineries and craft areas and whatever, I guess)</li><li>FINALLY FINDING A QUEEN BEE OMG AUGH FINALLY</li></ul></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/games/'>games</a>, <a class='category' href='/blog/categories/video-games/'>video games</a>
  
</span>

</a>


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/04/operating-systems-notes-deadlocks/">Operating Systems Notes [Deadlocks]</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-04T00:00:00-08:00" pubdate data-updated="true">Feb 4<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So.  Real talk.  I guess deadlocks kind of suck.<br /><br /><strong>A deadlock is an irreducible circular dependence</strong>.  You would use locks  to <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-6.html">synchronize</a> threads and keep them from messing with each other when they&#8217;re working on shared resources, like a global variable.<br /><br />When a deadlock happens, the two threads can&#8217;t advance because they each own a lock to a resource that the other one needs in order to continue on.<br /><br />Deadlocks can be visible as cycles.  In this next picture, process P1 has R1 and only needs R2 to proceed.  However, P2 owns R2 and needs R1 to proceed.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw0_-YLnBI/AAAAAAAAAFM/Fqt7QcRHTOM/s1600/deadlock1.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="166" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw0_-YLnBI/AAAAAAAAAFM/Fqt7QcRHTOM/s320/deadlock1.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">and so, unhappiness abounds</td></tr></tbody></table><br /><br />A cycle doesn&#8217;t necessarily always signal a deadlock, however, as in this picture.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/_SdPKamJbrgg/TUw2F2J0RXI/AAAAAAAAAFU/WT2g1Yhukg8/s1600/deadlock2.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="320" src="http://2.bp.blogspot.com/_SdPKamJbrgg/TUw2F2J0RXI/AAAAAAAAAFU/WT2g1Yhukg8/s320/deadlock2.jpg" width="206" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">yaaaaay</td></tr></tbody></table><br />Here, you would think there would be a cycle involving the processes P1 and P3, and the resources R1 and R2.  But, P2 could potentially release its ownership of the resource R1, and then P1 would be able to advance, and then the cycle would be broken.   Thus the <em>irreducible</em> part of the definition of deadlocks.  A graph can be reduced if a thread within that graph can have all of its requests granted.<br /><br /><br />In the case of code, a deadlock could look something like this.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw4Mx7zGTI/AAAAAAAAAFc/11kExpNbcBs/s1600/deadlock3.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="124" src="http://1.bp.blogspot.com/_SdPKamJbrgg/TUw4Mx7zGTI/AAAAAAAAAFc/11kExpNbcBs/s320/deadlock3.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">:(</td></tr></tbody></table><br />A deadlock happens in this case if Thread1 and Thread2 are running simultaneously, and Thread1 acquires lock A and Thread2 acquires lock B.  Then, they both need the lock that the other thread has to proceed.  No advancement.<br /><br />One way to deal with a case like this would be to make a function which would grab two locks for a thread simultaneously, instead of one at a time.<br /><br /><br /><span class="sig">Avoiding Deadlocks</span><br />There are three methods you can use to avoid deadlocks: preventative, avoidance, and detection.<br /><br /><strong>Prevention</strong> is a static method of avoidance.  You can make sure each thread obtains all the locks that it needs, and waits until all are available before moving.  The downside to this method is that you may end up making the system move more slowly &#8211; ideally you want some threads to do what work they can do with what they&#8217;ve got, not having to wait.  This is called <em>hold and wait</em>.<br /><br />In <em>circular wait</em>, resources are ordered, which means threads obtain locks to the resources in sequence.  This works because you won&#8217;t have threads grabbing things out of order and causing deadlocks.  But there&#8217;s disadvantages too: new locks will need to be added to the right spot, <em>all</em> resources would have to be ordered, including drives and networks and things, and how would you determine how to order those resources?  It&#8217;s kind of messy.<br /><br /><strong>Avoidance</strong> is a dynamic way of dealing with deadlocks, meaning I think that the system handles it, rather than the threads themselves.  There&#8217;s also a <em>circular wait</em>, but it&#8217;s different.  In avoidance, each thread states how many resources it needs max, and the system uses the Banker&#8217;s Algorithm on the request to see if the system could allocate that max to that thread, and still have enough resources remaining to let all the other threads finish their execution.<br /><br />Basically, with every thread&#8217;s request for its max resources, do this:<ul><li>Pretend that you granted the request</li><li>Pretend that you granted everyone else&#8217;s requests too</li><li>Can the resulting graph of threads and resources (as above) be reduced?</li><li>If yes, allocate the requested resource to that first requesting thread.  If not, block dat thread!</li></ul><br />With <strong>detection</strong>, also dynamic, the technique is to check to see if there&#8217;s a deadlock, and then eliminate it when you find one.  I&#8217;m pretty sure databases do a lot of stuff like this.  It&#8217;s easy to see if a deadlock has occurred already because the OS or relevant scheduler is aware of the processes and resources that are using/in use, so once you&#8217;ve found a deadlock, you should restart one of the threads, and hopefully that thread will have enough resources to run again in the next millisecond or two.  <br /><br /><br /><br />Sources:<br />section 5 notes<br />lecture 9 notes<br /><a href="http://en.wikipedia.org/wiki/Deadlock#Detection">Wikipedia: Deadlock Detection</a></div>
</div>
  
  
  <div class="category-bit">Categories: 

<span class="categories">
  
    <a class='category' href='/blog/categories/compsci/'>compsci</a>, <a class='category' href='/blog/categories/notes/'>notes</a>, <a class='category' href='/blog/categories/operating-systems/'>operating systems</a>
  
</span>

</a>


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/27/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/25/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About</h1>
  I&#8217;m Nadine. I like various things.  
</section>
<section>
  <h1>Other Places</h1>
  <ul>
    <li><a href="http://uxunicorn.com">Portfolio</a></li>
    <li><a href="http://neauro.tumblr.com">Tumblr</a></li>
    <li><a href="http://github.com/neauro">Github</a></li>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - nadine a. -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
